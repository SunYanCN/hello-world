
gswewf@gswewf-PC:~ docker pull taskrabbit/elasticsearch-dump
Using default tag: latest
latest: Pulling from taskrabbit/elasticsearch-dump
1160f4abea84: Pull complete
6e17e6655d0c: Pull complete
Digest: sha256:06a1a35aa62fc3326565d5cbac428f42486889d813c99d38b0996c18e83e9f71
Status: Downloaded newer image for taskrabbit/elasticsearch-dump:latest

Example:
# 从一个机器迁移索引及数据到另一个机器:
# 第一步： 拷贝analyzer如分词
gswewf@gswewf-PC:~$ docker run --rm -ti taskrabbit/elasticsearch-dump   --input=http://192.168.3.145:9200/dingding500_faq   --output=http://192.168.3.133:18200/dingding500_faq   --type=analyzer
# 第二步： 拷贝映射
gswewf@gswewf-PC:~$ docker run --rm -ti taskrabbit/elasticsearch-dump   --input=http://192.168.3.105:9200/mingcijieshi   --output=http://192.168.3.133:9200/mingcijieshi   --type=mapping
# 第三步： 拷贝数据
gswewf@gswewf-PC:~$ docker run --rm -ti taskrabbit/elasticsearch-dump   --input=http://192.168.3.105:9200/mingcijieshi   --output=http://192.168.3.133:9200/mingcijieshi   --type=data

# 若迁移数据需要提供登录认证：
gswewf@gswewf-PC:~/yhb/es_search$ docker run --rm -ti taskrabbit/elasticsearch-dump   --input="http://192.168.3.105:9200/jrtz_kg_entity_synonyms_20180404_111151"   --output="http://elastic:web12008@192.168.3.145:9200/jrtz_kg_entity_synonyms_20180404_111151"  --type=data

以上数据迁移的时候，会丢失对应的索引别名信息；

docker run --rm -ti taskrabbit/elasticsearch-dump \
  --input=http://192.168.3.250:9200/my_index \
  --output=http://192.168.3.105:9200/my_index \
  --type=mapping
docker run --rm -ti taskrabbit/elasticsearch-dump \
  --input=http://192.168.3.250:9200/my_index \
  --output=http://192.168.3.105:9200/my_index \
  --type=data

# 备份索引数据到一个文件:
docker run --rm -ti -v /data:/tmp taskrabbit/elasticsearch-dump \
  --input=http://192.168.3.250:9200/my_index \
  --output=/tmp/my_index_mapping.json \
  --type=mapping

gswewf@gswewf-PC:~/docker/elasticsearch$ docker run --rm  -ti -v $PWD/esdata:/data taskrabbit/elasticsearch-dump   --input=http://192.168.3.105:9200/all_baoxian_templates_answer_alias   --output=/data/all_baoxian_templates_answer_alias.json   --type=data

如果需要用 localhost 作为es的host：
docker run --net=host --rm -ti taskrabbit/elasticsearch-dump \
  --input=http://192.168.3.105:9200/my_index \
  --output=http://localhost:9200/my_index \
  --type=data


若不使用docker，则需要安装数据导入、导出插件
　　sudo apt-get install nodejs
　　sudo apt-get install npm
　　sudo npm install elasticdump -g
从数据库导出某个索引数据到文件：
gswewf@gswewf-pc:~$ elasticdump --input=http://localhost:9200/music-index --output=/home/gswewf/ambbr-ai/ambbr/music-index.json --all=true
从数据库导出所有索引数据到文件：
gswewf@gswewf-pc:~$ elasticdump --input=http://localhost:9200 --output=/home/gswewf/ambbr-ai/ambbr/Elasticsearch_all_data.json --all=true

从文件导入数据到数据库：
gswewf@gswewf-pc:~$ elasticdump --input=/home/gswewf/ambbr-ai/ambbr/music-index.json --output=http://localhost:9200/music-index3 --all=true

从一个数据库导出一个索引到另一个数据库：
gswewf@gswewf-pc:~$ elasticdump --input=http://localhost:9200/xplan_story_info --output=http://172.26.1.196:9200/xplan_story_info --all=true

elasticdump --input=http://localhost:9200/music-index --output=http://172.26.1.196:9200/music-index --all=true
elasticdump --input=http://172.26.1.196:9200/search-index/test --output=http://localhost:9200/qa-search-index/test --type=mapping
elasticdump --input=http://localhost:9200/qa-search-index/test --output=http://172.26.1.196:9200/qa-search-index/test --all=true


gswewf@gswewf-pc:~$ elasticdump --input=http://localhost:9200/music-index --output=http://172.26.1.196:9200/music-index --type=mapping
gswewf@gswewf-pc:~$ elasticdump --input=http://localhost:9200/music-index --output=http://172.26.1.196:9200/music-index --all=true


gswewf@gswewf-pc:~$ curl -XPUT localhost:9200/qa-search-index
gswewf@gswewf-pc:~$ curl -XPUT localhost:9200/qa-search-index/test/_mapping?pretty -d '{"test":{"properties":{"expression": {"type": "string"},"answer": {"type": "string"},"lib": {"type": "string"},"skill": {"type": "string"},"name": {"type": "string"},"id": {"type": "string"},"label": {"type": "string"},"keyword":{"type": "string"},"content": {"analyzer": "ik_max_word","type": "string"}}}}'

elasticdump --input=http://localhost:9200/qa-search-index --output=http://172.26.1.196:9200/qa-search-index --type=mapping
elasticdump --input=http://localhost:9200/qa-search-index --output=http://172.26.1.196:9200/qa-search-index --all=true

./elasticdump  --input=http://192.168.1.1:9200/original --output=http://192.168.1.2:9200/newCopy --type=mapping
--type=mapping ，意思是把原始索引的mapping结构迁移给目标索引。
然后在执行--type=data的
./elasticdump  --input=http://192.168.1.1:9200/original --output=http://192.168.1.2:9200/newCopy --type=data
就可以把数据迁移过去啦
如果索引很多，你还是懒得一个个去迁移，那么你可以改用这个命令：
./elasticdump  --input=http://192.168.1.1:9200/ --output=http://192.168.1.2:9200/ --all=true
加个--all=true，input与output里不需要把索引名加上，这样就可以自动把原机器上的所有索引迁移到目标机器


导出Mapping信息
elasticdump --ignore-errors=true  --scrollTime=120m  --bulk=true --input=http://10.10.20.164:9200/xmonitor-2015.04.29   --output=http://192.168.100.72:9200/xmonitor-prd-2015.04.29  --type=mapping

导出数据
elasticdump --ignore-errors=true  --scrollTime=120m  --bulk=true --input=http://10.10.20.164:9200/xmonitor-2015.04.28   --output=/usr/local/esdump/node-v0.12.2-linux-x64/data/xmonitor-prd-2015.04.28.json --type=data

导出数据到本地集群
elasticdump --ignore-errors=true  --scrollTime=120m  --bulk=true --input=http://10.10.20.164:9200/xmonitor-2015.04.29   --output=http://192.168.100.72:9200/xmonitor-prd-2015.04.29 --type=data

# Copy an index from production to staging with analyzer and mapping:
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=analyzer
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=mapping
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=data

# Backup index data to a file:
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=/data/my_index_mapping.json \
  --type=mapping
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=/data/my_index.json \
  --type=data
# Backup and index to a gzip using stdout:
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=$ \
  | gzip > /data/my_index.json.gz

# Backup the results of a query to a file
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=query.json \
  --searchBody '{"query":{"term":{"username": "admin"}}}'

# Copy a single index from a elasticsearch:
elasticdump \
  --input=http://es.com:9200/api/search \
  --input-index=my_index \
  --output=http://es.com:9200/api/search \
  --output-index=my_index \
  --type=mapping

# Copy a single type:
elasticdump \
  --input=http://es.com:9200/api/search \
  --input-index=my_index/my_type \
  --output=http://es.com:9200/api/search \
  --output-index=my_index \
  --type=mapping

# Copy a single type:
elasticdump \
  --input=http://es.com:9200/api/search \
  --input-index=my_index/my_type \
  --output=http://es.com:9200/api/search \
  --output-index=my_index \
  --type=mapping


# 当是单机，单节点时，且版本也一致，可以直接复制对应索引的数据到另外服务器：
1、查询索引对应是uuid:
gswewf@gswewf-PC:~$ curl -XGET 'localhost:9200/_cat/indices?v'
health status index                            uuid                   pri rep docs.count docs.deleted store.size pri.store.size
yellow open   blog                             u9cPLNNbTXKJfkXkPfrJ8A   5   1          1            0      5.4kb          5.4kb
yellow open   my_index                         i6cQ1GVaTC2hvpizSZv27Q   5   1          2            0     13.9kb         13.9kb
yellow open   baike                            B5_0Mbb-S1aHtKKJp1mbhw   5   1       4814            0      8.7mb          8.7mb
yellow open   ceshi_baike                      IPY7GXKlQgiLqN4E_CRN-w   5   1          3            0     21.7kb         21.7kb
yellow open   dingding500_faq                   mI8GODPAQ--NMgUIwqFDkw   5   1     139053            0     93.4mb         93.4mb
yellow open   dingding7500_faq                  1ijC2x6DQf2TMxUgbVDQ4Q   5   1    1647769            0    702.2mb        702.2mb
yellow open   baike_faq                        H3Q7LAUcQICWBrQXTFl-SQ   5   1          0            0       960b           960b
yellow open   jykl_noun_explanation NI693MdwSEuT9ejZk4g1Rw   5   1      46556            0    277.4mb        277.4mb
yellow open   xinxin_faq                     biFkTYQAT2myWlTsXQYwGw   5   1       1145            0      1.7mb          1.7mb
yellow open   jykl_faq              iIrJ4GrXSdiwKFNeocXRbg   5   1      46556        18956    451.2mb        451.2mb

2、复制数据目录
gswewf@gswewf-PC:~/docker/elasticsearch/esdata/nodes/0/indices$ ls
1ijC2x6DQf2TMxUgbVDQ4Q  biFkTYQAT2myWlTsXQYwGw  i6cQ1GVaTC2hvpizSZv27Q  IPY7GXKlQgiLqN4E_CRN-w  NI693MdwSEuT9ejZk4g1Rw
B5_0Mbb-S1aHtKKJp1mbhw  H3Q7LAUcQICWBrQXTFl-SQ  iIrJ4GrXSdiwKFNeocXRbg  mI8GODPAQ--NMgUIwqFDkw  u9cPLNNbTXKJfkXkPfrJ8A
gswewf@gswewf-PC:~/docker/elasticsearch/esdata/nodes/0/indices$ scp -r B5_0Mbb-S1aHtKKJp1mbhw new40:/home/ubuntu/docker/elasticsearch/esdata/nodes/0/indices/

以上会保留索引的别名信息。

# 更多的数据迁移使用帮助：
https://www.npmjs.com/package/elasticdump

# 单个索引数据迁移：
# 导出数据到文件：
gswewf@gswewf-PC:~$ docker run --rm  -ti -v $PWD/data:/data taskrabbit/elasticsearch-dump --input=http://192.168.3.105:9200/all_baoxian_templates_answer_alias   --output=/data/all_baoxian_templates_answer_alias.json   --type=data

批量迁移：
# 导出数据到文件
gswewf@gswewf-PC:~/yhb/es_search$ docker run --rm -ti -v "$PWD/data:/data" taskrabbit/elasticsearch-dump /bin/multielasticdump --input="http://192.168.3.105:9200" --output="/data/jykl"
# 从文件中导入数据到es
gswewf@gswewf-PC:~/yhb/es_search$ docker run --rm -ti -v "$PWD/data:/data" taskrabbit/elasticsearch-dump /bin/multielasticdump --direction=load --output="http://elastic:web1_2008@192.168.3.145:9200" --input="/data/jykl"

# es集群扩容，缩容，有时候为了降本需要，可能需要对es集群进行缩容：
有如下5台主机，5个主节点，5个数据节点，共10个节点：
~]$ curl "192.168.3.150:9200/_cat/nodes?v"
ip           heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
192.168.3.150           47          26   0    0.01    0.04     0.06 mdi       -      master-data-05
192.168.3.117           54          99   1    0.09    0.11     0.13 mdi       *      master-data-02
192.168.3.16            44          96   1    0.22    0.14     0.18 mdi       -      master-data-01
192.168.3.118           35          97   2    0.00    0.02     0.08 di        -      data-node-08
192.168.3.16            42          96   1    0.22    0.14     0.18 di        -      data-node-06
192.168.3.117           31          99   1    0.09    0.11     0.13 di        -      data-node-07
192.168.3.122           19          25   0    0.25    0.25     0.29 mdi       -      master-data-04
192.168.3.118           39          97   2    0.00    0.02     0.08 mdi       -      master-data-03
192.168.3.150           23          26   0    0.01    0.04     0.06 di        -      data-node-10
192.168.3.122           50          25   0    0.25    0.25     0.29 di        -      data-node-09
可通过如下命令，执行缩容命令
该命令会将192.168.3.150,192.168.3.122这两台节点上的数据，迁移到 192.168.3.16、192.168.3.117、192.168.3.118
curl -H "Content-Type: application/json" -XPUT 192.168.3.16:9200/_cluster/settings -d '{"transient": {"cluster.routing.allocation.exclude._ip": "192.168.3.150,192.168.3.122"}}' 
命令执行完成后，后台会执行数据迁移动作
等最终迁移完，通过下面命令查询，总节点数还是不变的：
curl '192.168.3.16:9200/_cat/nodes?v'
通过下面命令查询，发现是没有分片数据在192.168.3.122，192.168.3.150
curl '192.168.3.117:9200/_cat/shards?v'
通过下面命令可以查询健康状态及正在迁移分片数：
curl -XGET '192.168.3.16:9200/_cluster/health?pretty'
{
  "cluster_name" : "tts-bancas",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 10,
  "number_of_data_nodes" : 10,
  "active_primary_shards" : 2118,
  "active_shards" : 4199,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}
解释：
cluster_name：集群名称。
status：集群健康状态（green、yellow、red）。
timed_out：请求是否超时。
number_of_nodes：集群中的节点数量。
number_of_data_nodes：集群中的数据节点数量。
active_primary_shards：活动的主分片数量。
active_shards：活动的分片总数。
relocating_shards：正在迁移的分片数量。
initializing_shards：正在初始化的分片数量。
unassigned_shards：未分配的分片数量。
delayed_unassigned_shards：延迟未分配的分片数量。
number_of_pending_tasks：待处理任务的数量。
number_of_in_flight_fetch：正在获取的分片数量。
task_max_waiting_in_queue_millis：任务在队列中等待的最长时间（毫秒）。
active_shards_percent_as_number：活动分片的百分比。
降低`discovery.zen.minimum_master_nodes`设置以保证多数派选举可以正常进行。如果你之前是3个主节点，可能需要将其降至2（但请注意这降低了集群的耐故障性）。修改这个设置并应用：
curl -H 'Content-Type: application/json' -X PUT 192.168.3.16:9200/_cluster/settings -d'
   {
     "persistent": {
       "discovery.zen.minimum_master_nodes": 2
     }
   }'
还需下一步：1、关闭不需要的节点；2、修改配置文件移除即将停用的节点，防止重启时自动加入集群。

扩容，则与缩容相反：
手动指定 shard 分配到新增节点
PUT _cluster/_settings
{
  "index.routing.allocation.include._ip": "x.x.x.x,y.y.y.y"
}




