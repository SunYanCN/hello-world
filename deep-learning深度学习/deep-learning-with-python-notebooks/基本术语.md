
# 类(class)
    在机器学习中,分类问题中的某个类别叫作类(class)。

# 样本(sample)
    数据点叫作样本(sample)。

# 标签(label)
    某个样本对应的类叫作标签(label)。

# 张量(tensor)
    是一个数据容器。它包含的数据几乎总是数值数据,因此它是数字的容器。你可能对矩阵很熟悉,它是二维张量。
    张量是矩阵向任意维度的推广[注意,张量的维度(dimension)通常叫作轴(axis)]。

# 维度(dimension)
    可以表示沿着某个轴上的元素个数(比如 5D 向量),也可以表示张量中轴的个数(比如 5D 张量),这有时会令人感到混乱。
    对于后一种情况,技术上更准确的说法是 5 阶张量(张量的阶数即轴的个数),但 5D 张量这种模糊的写法更常见。

# 轴(axis)

# 样本轴
    通常来说,深度学习中所有数据张量的第一个轴(0 轴,因为索引从 0 开始)都是样本轴(samples axis,有时也叫样本维度)

# 批量
    深度学习模型不会同时处理整个数据集,而是将数据拆分成小批量。
    具体来看,下面是 MNIST 数据集的一个批量,批量大小为 128。
    batch = train_images[:128]
    然后是下一个批量。
    batch = train_images[128:256]
    然后是第 n 个批量。
    batch = train_images[128 * n:128 * (n + 1)]
    对于这种批量张量,第一个轴(0 轴)叫作批量轴(batch axis)或批量维度(batch dimension)。

# 向量数据
    2D 张量,形状为 (samples, features) 。
    对于这种数据集,每个数据点都被编码为一个向量,因此一个数据批量就被编码为 2D 张量(即向量组成的数组),其中第一个轴是样本轴,第二个轴是特征轴。

# 时间序列数据或序列数据
    3D 张量,形状为 (samples, timesteps, features) 。
    当时间(或序列顺序)对于数据很重要时,应该将数据存储在带有时间轴的 3D 张量中。
    每个样本可以被编码为一个向量序列(即 2D 张量),因此一个数据批量就被编码为一个 3D 张量。
    根据惯例,时间轴始终是第 2 个轴(索引为 1 的轴)。

# 图像
    4D 张量,形状为 (samples, height, width, channels) 或 (samples, channels,height, width) 。
    图像通常具有三个维度:高度、宽度和颜色深度。
    虽然灰度图像(比如 MNIST 数字图像)只有一个颜色通道,因此可以保存在 2D 张量中,但按照惯例,图像张量始终都是 3D 张量,灰度图像的彩色通道只有一维。
    因此,如果图像大小为 256×256,那么 128 张灰度图像组成的批量可以保存在一个形状为 (128, 256, 256, 1) 的张量中,
    而 128 张彩色图像组成的批量则可以保存在一个形状为 (128, 256, 256, 3) 的张量中。
    图像张量的形状有两种约定:通道在后(channels-last)的约定(在 TensorFlow 中使用)和通道在前(channels-first)的约定(在 Theano 中使用)。
    Google 的 TensorFlow 机器学习框架将颜色深度轴放在最后: (samples, height, width, color_depth) 。
    与此相反,Theano将图像深度轴放在批量轴之后: (samples, color_depth, height, width) 。
    如果采用 Theano 约定,前面的两个例子将变成 (128, 1, 256, 256) 和 (128, 3, 256, 256) 。
    Keras 框架同时支持这两种格式。

# 视频
    5D 张量,形状为 (samples, frames, height, width, channels) 或 (samples,frames, channels, height, width) 。
    视频数据是现实生活中需要用到 5D 张量的少数数据类型之一。视频可以看作一系列帧,每一帧都是一张彩色图像。
    由于每一帧都可以保存在一个形状为 (height, width, color_depth) 的 3D 张量中,
    因此一系列帧可以保存在一个形状为 (frames, height, width, color_depth) 的 4D 张量中,
    而不同视频组成的批量则可以保存在一个 5D 张量中,其形状为(samples, frames, height, width, color_depth) 。

# 广播(broadcast)
    将一个 2D 张量与一个向量相加。如果将两个形状不同的张量相加,如果没有歧义的话,较小的张量会被广播(broadcast),以匹配较大张量的形状。
    广播包含以下两步。
    (1) 向较小的张量添加轴(叫作广播轴),使其 ndim 与较大的张量相同。
    (2) 将较小的张量沿着新轴重复,使其形状与较大的张量相同。

# 张量点积
    点积运算,也叫张量积(tensor product,不要与逐元素的乘积弄混),是最常见也最有用的张量运算。
    与逐元素的运算不同,它将输入张量的元素合并在一起。
    注意,两个向量之间的点积是一个标量,而且只有元素个数相同的向量之间才能做点积。
    对一个矩阵 x 和一个向量 y 做点积,返回值是一个向量,其中每个元素是 y 和 x的每一行之间的点积。

# 张量变形(tensor reshaping)
    张量变形是指改变张量的行和列,以得到想要的形状。变形后的张量的元素总个数与初始张量相同。
    简单的例子可以帮助我们理解张量变形。
    >>> x = np.array([[0., 1.],
                                    [2., 3.],
                                    [4., 5.]])
    >>> print(x.shape)
    (3, 2)
    >>> x = x.reshape((6, 1))
    >>> x
    array([[ 0.],
    [ 1.],
    [ 2.],
    [ 3.],
    [ 4.],
    [ 5.]])
    >>> x = x.reshape((2, 3))
    >>> x
    array([[ 0., 1., 2.],
                [ 3., 4., 5.]])

# 阶(rank)
    张量轴的个数也叫作阶(rank)。
    例如,3D 张量有 3 个轴,矩阵有 2 个轴。这在 Numpy 等 Python 库中也叫张量的 ndim 。
    >>> x = np.random.random((3, 2))
    >>> x
    array([[0.8957804 , 0.96712402],
           [0.73855227, 0.34115149],
           [0.36667734, 0.16249242]])
    >>> x.ndim
    2

# 形状
    这是一个整数元组,表示张量沿每个轴的维度大小(元素个数)。
    例如,前面矩阵示例的形状为 (3, 5) ,3D 张量示例的形状为 (3, 3, 5) 。
    向量的形状只包含一个元素,比如 (5,) ,而标量的形状为空,即 () 。
    >>> x = np.array(3)
    >>> x.shape
    ()
    >>> x = np.array([2,3])
    >>> x.shape
    (2,)

# 数据类型(在 Python 库中通常叫作 dtype )
    这是张量中所包含数据的类型,例如,张量的类型可以是 float32 、 uint8 、 float64 等。
    在极少数情况下,你可能会遇到字符( char )张量。
    注意,Numpy(以及大多数其他库)中不存在字符串张量,因为张量存储在预先分配的连续内存段中,而字符串的长度是可变的,无法用这种方式存储。
    >>> x = np.array([2.0,3])
    >>> x.dtype
    dtype('float64')

# 标量(scalar, 0D 张量)
    仅包含一个数字的张量叫作标量(scalar,也叫标量张量、零维张量、0D 张量)。
    在 Numpy中,一个 float32 或 float64 的数字就是一个标量张量(或标量数组)。
    你可以用 ndim 属性来查看一个 Numpy 张量的轴的个数。标量张量有 0 个轴( ndim == 0 )。
    张量轴的个数也叫作阶(rank)。下面是一个 Numpy 标量。
    >>> import numpy as np
    >>> x = np.array(12)
    >>> x
    array(12)
    >>> x.ndim
    0

# 向量(vector, 1D 张量)
    数字组成的数组叫作向量(vector)或一维张量(1D 张量)。一维张量只有一个轴。
    下面是一个 Numpy 向量。
    >>> x = np.array([12, 3, 6, 14, 7])
    >>> x
    array([12, 3, 6, 14, 7])
    >>> x.ndim
    1

    这个向量有 5 个元素,所以被称为 5D 向量。不要把 5D 向量和 5D 张量弄混!
    5D 向量只有一个轴,沿着轴有 5 个维度,而 5D 张量有 5 个轴(沿着每个轴可能有任意个维度)。

# 矩阵(matrix, 2D 张量)
    向量组成的数组叫作矩阵(matrix)或二维张量(2D 张量)。
    矩阵有 2 个轴(通常叫作行和列)。你可以将矩阵直观地理解为数字组成的矩形网格。
    下面是一个 Numpy 矩阵。
    >>> x = np.array([[5, 78, 2, 34, 0],
                                    [6, 79, 3, 35, 1],
                                    [7, 80, 4, 36, 2]])
    >>> x.ndim
    2
    第一个轴上的元素叫作行(row),第二个轴上的元素叫作列(column)。
    在上面的例子中,[5, 78, 2, 34, 0] 是 x 的第一行, [5, 6, 7] 是第一列。

# 3D 张量
    将多个矩阵组合成一个新的数组,可以得到一个 3D 张量,你可以将其直观地理解为数字组成的立方体。
    下面是一个 Numpy 的 3D 张量。
    >>> x = np.random.random((3, 2, 4))
    >>> x
    array([[[0.12988825, 0.77277393, 0.46243809, 0.12377541],
            [0.8033865 , 0.81821495, 0.22307274, 0.52566756]],
           [[0.80553673, 0.79450534, 0.14504729, 0.60237352],
            [0.03084524, 0.12027406, 0.45299607, 0.05332909]],
           [[0.68057101, 0.81951978, 0.65863182, 0.85608584],
            [0.68971186, 0.01891051, 0.17315731, 0.02773519]]])
    >>> x.ndim
    3

# 高维张量
    将多个 3D 张量组合成一个数组,可以创建一个 4D 张量,以此类推。
    深度学习处理的一般是 0D 到 4D 的张量,但处理视频数据时可能会遇到 5D 张量。

# 训练集(training set)

# 测试集(test set）

# 权重(weight)或可训练参数(trainable parameter)
    权重是利用随机梯度下降学到的一个或多个张量,其中包含网络的知识。

# 层(layer)
    神经网络的核心组件是层(layer),它是一种数据处理模块,你可以将它看成数据过滤器。
    进去一些数据,出来的数据变得更加有用。具体来说,层从输入数据中提取表示——我们期望这种表示有助于解决手头的问题。
    大多数深度学习都是将简单的层链接起来,从而实现渐进式的数据蒸馏(data distillation)。
    深度学习模型就像是数据处理的筛子,包含一系列越来越精细的数据过滤器(即层)。
    层是一个数据处理模块,将一个或多个输入张量转换为一个或多个输出张量。有些层是无状态的,但大多数的层是有状态的,即层的权重。

# 密集层(dense layer, Dense 层)
    密集连接(也叫全连接)的神经层。
    密集连接层[densely connected layer,也叫全连接层(fully connected layer)或密集层(dense layer),对应于 Keras 的 Dense 类]来处理。

# 循环层(recurrent layer,比如 Keras 的 LSTM 层)

# 二维卷积层(Keras 的 Conv2D )

# softmax 层

# 编译(compile)

# 拟合(fit)

# 过拟合(overfit)
    过拟合是指机器学习模型在新数据上的性能往往比在训练数据上要差

# 损失( loss )

# 精度( acc )

# 损失函数(loss function)
    网络如何衡量在训练数据上的性能,即网络如何朝着正确的方向前进。
    该函数也叫目标函数(objective function)。
    损失函数的输入是网络预测值与真实目标值(即你希望网络输出的结果),然后计算一个距离值,衡量该网络在这个示例上的效果好坏。
    损失函数(目标函数)——在训练过程中需要将其最小化。它能够衡量当前任务是否已成功完成。

# 优化器(optimizer)
    基于训练数据和损失函数来更新网络的机制。
    利用网络预测值与真实目标值的距离值作为反馈信号来对权重值进行微调,以降低当前示例对应的损失值。
    优化器——决定如何基于损失函数对网络进行更新。它执行的是随机梯度下降(SGD)的某个变体。

# 指标(metric)

# 轮次(epoch)
    在所有训练数据上迭代一次叫作一个轮次(epoch)

# 模型的深度(depth)
    数据模型中包含多少层,这被称为模型的深度(depth)。

# logistic 回归(logistic regression,简称 logreg)
    logreg 是一种分类算法,而不是回归算法。

# 监督学习(supervised learning)
    监督学习是目前最常见的机器学习类型。给定一组样本(通常由人工标注),它可以学会将输入数据映射到已知目标[也叫标注(annotation)]。
    其目标是学习训练输入与训练目标之间的关系。

# 序列生成(sequence generation)
    给定一张图像,预测描述图像的文字。序列生成有时可以被重新表示为一系列分类问题,比如反复预测序列中的单词或标记。

#  语法树预测(syntax tree prediction)
    给定一个句子,预测其分解生成的语法树。

# 目标检测(object detection)
    给定一张图像,在图中特定目标的周围画一个边界框。这个问题也可以表示为分类问题(给定多个候选边界框,对每个框内的目标进行分类)或分类与回归联合问题(用向量回归来预测边界框的坐标)。

# 图像分割(image segmentation)
    给定一张图像,在特定物体上画一个像素级的掩模(mask)

# 降维(dimensionality reduction)

# 聚类(clustering)

# 样本(sample)或输入(input)
    进入模型的数据点。

# 预测(prediction)或输出(output)
    从模型出来的结果。

# 目标(target)
    真实值。对于外部数据源,理想情况下,模型应该能够预测出目标。

# 预测误差(prediction error)或损失值(loss value)
    模型预测与目标之间的距离。

# 类别(class)
    分类问题中供选择的一组标签。例如,对猫狗图像进行分类时,“狗”和“猫”就是两个类别。

# 标签(label)
    分类问题中类别标注的具体例子。比如,如果 1234 号图像被标注为

# 真值(ground-truth)或标注(annotation)
    数据集的所有目标,通常由人工收集。
# 二分类(binary classification)
    一种分类任务,每个输入样本都应被划分到两个互斥的类别中。

# 多分类(multiclass classification)
    一种分类任务,每个输入样本都应被划分到两个以上的类别中,比如手写数字分类。

# 多标签分类(multilabel classification)
    一种分类任务,每个输入样本都可以分配多个标签。
    举个例子,如果一幅图像里可能既有猫又有狗,那么应该同时标注“猫”标签和“狗”标签。每幅图像的标签个数通常是可变的。

# 标量回归(scalar regression)
    目标是连续标量值的任务。预测房价就是一个很好的例子,不同的目标价格形成一个连续的空间。

# 向量回归(vector regression)
    目标是一组连续值(比如一个连续向量)的任务。如果对多个值(比如图像边界框的坐标)进行回归,那就是向量回归。

# 小批量(mini-batch)或批量(batch)
    模型同时处理的一小部分样本(样本数通常为 8~128)。
    样本数通常取 2 的幂,这样便于 GPU 上的内存分配。
    训练时,小批量用来为模型权重计算一次梯度下降更新。

# 特征图(feature map)
    对于包含两个空间轴(高度和宽度)和一个深度轴(也叫通道轴)的 3D 张量,其卷积也叫特征图(feature map)。

# 填充(padding)
    填充(padding)是指在输入高和宽的两侧填充元素(通常是 0 元素)。

# 步幅(stride)
    在卷积神经网络中，卷积窗口从输入数组的最左上方开始,按从左往右、从上往下的顺序,依次在输入数组上滑动。我们将每次滑动的行数和列数称为步幅(stride)。

# 范数(norm)
    距离的定义是一个宽泛的概念，只要满足非负、自反、三角不等式就可以称之为距离。
    范数是一种强化了的距离概念，它在定义上比距离多了一条数乘的运算法则。
    有时候为了便于理解，我们可以把范数当作距离来理解。
    范数是把一个事物映射到非负实数，且满足非负性、齐次性、三角不等式，符合以上定义的都可以称之为范数
    范数包括向量范数和矩阵范数
    不同的范数表示不同的度量方法，就好比米和光年都可以来度量远近一样；
    
# 向量范数
    向量范数表征向量空间中向量的大小.
    一种非严密的解释就是，对应向量范数，向量空间中的向量都是有大小的，这个大小如何度量，就是用范数来度量的，
    不同的范数都可以来度量这个大小，就好比米和光年都可以来度量远近一样；

    L0范数： L0范数表示向量中非零元素的个数。
    1-范数：，即向量元素绝对值之和; np.linalg.norm([1,2,3], ord=1)
    2-范数：，Euclid范数（欧几里得范数，常用计算向量长度），即向量元素绝对值的平方和再开方;
                np.linalg.norm([1,2,3], ord=2)
                Out[13]: 3.7416573867739413
                math.pow(1*1+2*2+3*3, 0.5)
                Out[9]: 3.7416573867739413
    ∞-范数：，即所有向量元素绝对值中的最大值
                np.linalg.norm([1,2,3], ord=np.inf)
                Out[16]: 3.0
    -∞-范数：，即所有向量元素绝对值中的最小值。
                np.linalg.norm([1,2,3], ord=-np.inf)
                Out[17]: 1.0
    p-范数：，即向量元素绝对值的p次方和的1/p次幂。
    
# 矩阵特征值；特征向量
    设A是n阶方阵，如果数λ和n维非零列向量x使关系式Ax=λx成立，那么这样的数λ称为矩阵A特征值，非零向量x称为A的对应于特征值λ的特征向量。
    式Ax=λx也可写成( A-λE)X=0。这是n个未知数n个方程的齐次线性方程组，它有非零解的充分必要条件是系数行列式| A-λE|=0。
    np.linalg.eig(np.array([[1, 0, 0],
       [0, 5, 0],
       [0, 0, 9]]))
    Out[43]: 
    (array([1., 5., 9.]), array([[1., 0., 0.],
            [0., 1., 0.],
            [0., 0., 1.]]))

# 矩阵范数
    矩阵范数表征矩阵引起变化的大小。
    对于矩阵范数，通过运算AX=BAX=B，可以将向量X变化为B，矩阵范数就是来度量这个变化大小的。
    不同的范数都可以来度量这个大小，就好比米和尺都可以来度量远近一样；
    一个集合（向量），通过一种映射关系（矩阵），得到另外一个集合（另外一个向量）。
    矩阵的范数，就是表示这个变化过程的大小的一个度量。矩阵范数反映了线性映射把一个向量映射为另一个向量，向量的“长度”缩放的比例。
    1-范数：， 列和范数，即所有矩阵列向量绝对值之和的最大值，
                np.linalg.norm([[1,2,3], [4, 5, 6]], ord=1)
                Out[19]: 9.0
    2-范数：，谱范数，即AT·A矩阵的最大特征值的开平方。
                np.linalg.norm([[1,2,3], [4, 5, 6]], ord=2)
                Out[31]: 9.508032000695724
                x = np.array([[1,2,3], [4, 5, 6]])
                x.T
                Out[36]: 
                array([[1, 4],
                       [2, 5],
                       [3, 6]])
                np.dot(x.T, x)
                Out[37]: 
                array([[17, 22, 27],
                       [22, 29, 36],
                       [27, 36, 45]])
                # 计算特征值及特征向量       
                np.linalg.eig(np.dot(x.T, x))
                Out[38]: 
                (array([9.04026725e+01, 5.97327474e-01, 7.23299057e-16]),
                 array([[-0.42866713, -0.80596391,  0.40824829],
                        [-0.56630692, -0.11238241, -0.81649658],
                        [-0.7039467 ,  0.58119908,  0.40824829]]))
                math.pow(max(np.linalg.eig(np.dot(x.T, x))[0]), 0.5)
                Out[39]: 9.508032000695724

    ∞-范数：，行和范数，即所有矩阵行向量绝对值之和的最大值。
    F-范数：，Frobenius范数，即矩阵元素绝对值的平方和再开平方。
    
# 向量模长
    向量模长； 即向量元素绝对值的平方和再开方;
    向量的第二范数为传统意义上的向量长度
    向量的模，sum(vector**2)**0.5
    math.sqrt(sum(vec**2 for vec in vector))
    
# 矩阵乘积
    矩阵乘积; 矩阵相乘最重要的方法是一般矩阵乘积。
    它只有在第一个矩阵的列数（column）和第二个矩阵的行数（row）相同时才有意义  。
    np.dot([[1,2,3], [4, 5,6]], [[1,2], [3,4], [5,6]])
    Out[63]: 
    array([[22, 28],
           [49, 64]])

# 点乘运算
    就是对这两个向量对应位一一相乘之后求和的操作; 即：若a=(x1,y1),b=(x2,y2)，则a·b=x1·x2+y1·y2
    np.dot([1,2,3], [4,5,6])
    Out[4]: 32
    1*4 + 2*5 + 3*6
    Out[5]: 32
    
# np.dot
    1.对于一维数组，其作用同inner
    np.dot([1,2], [3,4])
    Out[75]: 11
    np.inner([1,2], [3,4])
    Out[76]: 11

    2.对于二维数组，其作用是矩阵乘法
    np.dot([[1,2,3], [4,5,6]], [[1,0,0], [1,2,3], [4,5,6]])
    Out[69]: 
    array([[15, 19, 24],
           [33, 40, 51]])
 
    对于多维数组，其作用是将数组a的最后轴上的所有元素与数组b的倒数第二轴上的所有元素的乘积和
    np.dot([[    [0, 2, 0],
                 [1,2,3]],
                [[1,2,3], 
                 [4,5,6]] ], 
            [[[1,0,0], 
              [1,1,1], 
              [0, 0, 0]],
            [[1,0,0], 
             [1,2,3], 
             [4,5,6]]])
    Out[80]: 
    array([[[[ 2,  2,  2],
             [ 2,  4,  6]],
            [[ 3,  2,  2],
             [15, 19, 24]]],
           [[[ 3,  2,  2],
             [15, 19, 24]],
            [[ 9,  5,  5],
             [33, 40, 51]]]])

# 点积
    点积，又叫点乘，向量内积、数量积,dot product; scalar product,标量积
    公式：a * b = |a| * |b| * cosθ = a1*b1 + a2*b2 + a3*b3 + ... + an*bn 
    这里要求一维向量a和向量b的行列数相同。
    点乘又叫向量的内积、数量积，是一个向量和它在另一个向量上的投影的长度的乘积；是标量。 
    点乘反映着两个向量的“相似度”，两个向量越“相似”，它们的点乘越大。
    对两个向量执行点乘运算，就是对这两个向量对应位一一相乘之后求和的操作，点乘的结果是一个标量。
    向量内积,向量a和b的长度之积再乘以它们之间的夹角的余弦；向量内积的几何解释就是一个向量在另一个向量上的投影的积
    内积指的是一个向量(在另一个向量上)的投影乘上另一个向量的模(可以理解为向量的长度)，如果内积为零，意思是互相之间没有投影。
    np.inner([1, 0], [1, 2])
    Out[52]: 1
    math.sqrt(sum(vec**2 for vec in [1, 0])) 
    Out[53]: 1.0
    math.sqrt(sum(vec**2 for vec in [1, 2])) 
    Out[54]: 2.23606797749979
    对于一维数组，np.dot 其作用同np.inner

    # 对于两个二维数组的inner，相当于按X和Y的最后顺序的轴方向上取向量，
    # 然后依次计算内积后组成的多维数组
    np.inner([[1,2,3], [4,5,6]], [[1,0,0], [1,2,3], [4,5,6]])
    Out[67]: 
    array([[ 1, 14, 32],
           [ 4, 32, 77]])
    
    [[np.dot([1,2,3], [1,0,0]), np.dot([1,2,3],  [1,2,3]), np.dot([1,2,3], [4,5,6])], 
    [np.dot([4,5,6], [1,0,0]), np.dot([4,5,6], [1,2,3]), np.dot([4,5,6], [4,5,6])]]
    Out[71]: [[1, 14, 32], 
              [4, 32, 77]]


# 正交基(Orthogonal Basis)
    三个向量两两之间互相的内积等于零，于是这三个向量就是一组简单的正交基。

# 标准正交基
    每组正交基中的向量，其模(可以认为是长度)的大小都是1，这样的情况称为标准正交基。

# 叉乘
    两个向量的叉乘，又叫向量积、外积、叉积，叉乘的运算结果是一个向量而不是一个标量。并且两个向量的叉积与这两个向量组成的坐标平面垂直。
    向量的叉乘，即求同时垂直两个向量的向量，即c垂直于a，同时c垂直于b（a与c的夹角为90°，b与c的夹角为90°）
    c =  a×b = （a.y*b.z-b.y*a.z , b.x*a.z-a.x*b.z  , a.x*b.y-b.x*a.y）
    在二维空间中，叉乘还有另外一个几何意义就是：aXb等于由向量a和向量b构成的平行四边形的面积。
    在三维几何中，向量a和向量b的叉乘结果是一个向量，更为熟知的叫法是法向量，该向量垂直于a和b向量构成的平面。
    两个向量的外积，又叫叉乘、叉积向量积，其运算结果是一个向量而不是一个标量。并且两个向量的外积与这两个向量组成的坐标平面垂直。
    定义：向量a与b的外积a×b是一个向量，其长度等于|a×b| = |a||b|sin∠(a,b)，其方向正交于a与b。并且，(a,b,a×b)构成右手系。 
    特别地，0×a = a×0 = 0.此外，对任意向量a，a×a=0。
    向量的叉乘：a ∧ b
    a ∧ b = |a| * |b| * sinθ 
    向量积被定义为： 
    模长：（在这里θ表示两向量之间的夹角(共起点的前提下)（0° ≤ θ ≤ 180°），它位于这两个矢量所定义的平面上。） 
    方向：a向量与b向量的向量积的方向与这两个向量所在平面垂直，且遵守右手定则。
    若坐标系是满足右手定则的，当右手的四指从a以不超过180度的转角转向b时，竖起的大拇指指向是c的方向。c = a ∧ b
    np.outer只对一维数组进行计算，如果传入的是多维数组，则先将此数组展平为一维数组之后再进行算。
    outer计算列向量和行向量的矩阵乘积，即结果为矩阵
    np.outer([1,2,3], [4,5,6])
    Out[72]: 
    array([[ 4,  5,  6],
           [ 8, 10, 12],
           [12, 15, 18]])
           
    [row * np.array([4,5,6]) for row in [1,2,3]]
    Out[74]: [array([4, 5, 6]), array([ 8, 10, 12]), array([12, 15, 18])]

# 张量积np.tensordot
    tensordot()将两个多维数组a和b指定轴上的对应元素相乘并求和，它是最一般化的乘积运算函数。
    np.tensordot(Z,X,axes=[[0],[1]]) #指定Z的0轴与X的1轴进行乘积求和
    a = np.arange(60.).reshape(3,4,5)
    b = np.arange(24.).reshape(4,3,2)
    c = np.tensordot(a,b, axes=([1,0],[0,1]))

    对于多维数组的dot乘积，相当于tensordot(a,b,axes=[[-1],[-2]])
    np.dot(X,Z) == np.tensordot(X,Z,axes=[[-1],[-2]])

# feature map 
    应该是特征图的意思，是指每个卷积核和输入卷积后形成的特征图，特征图的个数和卷积核的个数相同

# 卷积核
    
# 互相关（cross-correlation）
    互相关
    设两个函数分别是f(t)和g(t)，则互相关函数定义为：
    它反映的是两个函数在不同的相对位置上互相匹配的程度。
    对卷积不要求倒序操作，也就是互相关；互相关不满足交换律；

# 卷积
    卷积，就是信号B(数据B)与信号A(数据A)错开时间或空间的内积和，错开的时间或空间长度就是卷积结果的自变量。
    或者说，离散域的卷积就是数据A与数据B里面的一段数据逐个相乘，然后再加起来。
    这里的“一段”就是卷积核的长度，当然也可以是无限长。连续域就是把加起来换成积分。
    卷积的方式有三种：
    如果自始至终卷积核都在“信号内”，则最后得到的结果长度会小于待卷积信号长度。假设待卷积信号的长度是n,卷积核大小是m,则结果长度为n-m+1;这种卷积的方式称为 valid;
    如果卷积核的中心刚好从待卷积信号的第一个元素滑到最后一个元素，则需要把原来的信号扩展长度；一般来说扩展的方式是在原来信号的边缘添加0元素，这个过程通常称为零填充(zero padding);通过零填充，卷积结果的长度和待卷积信号长度一样，这种卷积的方式称为same;
    如果通过零填充把卷积核能够划过的位置扩展到最大，则结果长度为 n+m-1;这种方式称为full.
    
# 编码器（encoder）
    编码器（encoder）将输入数据转换为一种不同的表示

# 解码器（decoder）
    解码器函数将新的表示（经编码器处理后的表示）转换到原来的形式
    
# 自编码器(AE)
    自编码器（autoencoder）=编码器（encoder）+解码器（decoder）。
    自编码器是一种网络类型,其目的是将输入编码到低维潜在空间,然后再解码回来。
    自编码器学习对原始输入进行重新构建。通过对编码器的输出施加各种限制,我们可以让自编码器学到比较有趣的数据潜在表示。
    自编码器分成两个部分，第一个部分是encoder，一般是多层网络，将输入的数据压缩成为一个向量，变成低维度，而该向量就称之为瓶颈。第二个部分是decoder，灌之以瓶颈，输出数据，我们称之为重建输入数据。我们的目的是要让重建数据和原数据一样，以达到压缩还原的作用。
    缺点：低维度的瓶颈显然丢失了很多有用的信息，重建的数据效果并不好。

# 去噪自编码器(DAE)
    降噪自动编码器DAE是在自动编码器的基础上，训练数据加入噪声，来训练整个网络，以和AE相同的方式去训练，得到的网络模型便是DAE。
    在实际的测试数据中，噪声是不可避免的，采用有噪声的训练数据训练网络，神经网络就能够学习到不加噪声的输入特征和噪声的主要特征。能够使网络在测试数据中有更强的泛化能力。

# 变分自编码器(VAE,variational autoencoder)
    VAE和AE，DAE不同的是，原先编码器是映射成一个向量，现在是映射成两个向量，一个向量表示分布的平均值，另外一个表示分布的标准差，两个向量都是相同的正态分布。现在从两个向量分别采样，采样的数据灌给解码器。
    VAE 不是将输入压缩成潜在空间中的固定编码,而是将转换为统计分布的参数,即平均值和方差。
    本质上来说,这意味着我们假设输入是由统计过程生成的,在编码和解码过程中应该考虑这一过程的随机性。
    然后,VAE 使用平均值和方差这两个参数来从分布中随机采样一个元素,并将这个元素解码到原始输入。
    这个过程的随机性提高了其稳健性,并迫使潜在空间的任何位置都对应有意义的表示,即潜在空间采样的每个点都能解码为有效的输出。

# 去耦变分自编码器(β-VAE)
    β-VAE是VAE的变体，增强了VAE模型表示解耦(Disentanglement，解纠缠)的能力。仅需在loss function中加上一个β即可达到目的。
    loss函数中，β就是一个超参数，当β为1的时候，它就是标准的VAE。
    一个较高的β值，就使得前变量空间z表示信息的丰富度降低，但同时模型的解纠缠能力增加。所以β可以作为表示能力和解纠缠能力之间的平衡因子。
    
# 语言模型（Language Model）
    语言模型简单来说就是一串词序列的概率分布。
    
# 掩码(mask)
    掩码(Mask)表示屏蔽某些值，以便在更新参数时它们不起作用。
    变换器(Transformer)模型中有两种掩码:填充掩码和序列掩码。
    填充掩码用于所有缩放的点积注意，序列掩码仅用于解码器的自注意。
    填充掩码解决了输入序列具有可变长度的问题。具体来说，在较短的序列后填0。
    但是如果输入序列太长，则会截取左侧的内容，并直接丢弃多余的内容。因为这些填充的位置实际上没有意义，注意机制不应该集中在这些位置，所以需要做一些处理。
    具体方法是在这些位置的值上加一个非常大的负数（负无穷大），这样这些位置的概率在softmax计算之后将接近0！
    填充掩码实际上是一个张量，每个值都是一个布尔值，false值指想要处理的值。

# 掩码语言模型（Masked Language Model, MLM）
    MLM 随机遮蔽模型输入中的一些 token，目标在于仅基于遮蔽词的语境来预测其原始词汇 id。
    与从左到右的语言模型预训练不同，MLM 目标允许表征融合左右两侧的语境，从而预训练一个深度双向 Transformer。

# 句子预测(Next Sentense Prediction, NSP)
    在训练过程中，对于 sentenceA 和 sentenceB，随机选择 50% 对，
    将其中 sentenceB 置换成其他任意文本，然后标签为 0/1，从而构造成了二值分类任务。
    最终，pre-training 过程中，training loss 为平均 NSP 似然之和。

# 排列语言模型(Permutation Language Model, PLM)
    又称，乱序语言模型。
    PLM的本质就是LM联合概率的多种分解机制的体现；
    将LM的顺序拆解推广到随机拆解，但是需要保留每个词的原始位置信息（PLM只是语言模型建模方式的因式分解/排列，并不是词的位置信息的重新排列！）
    如果遍历 𝑇! 种分解方法，并且模型参数是共享的，PLM就一定可以学习到各种双向上下文；
    换句话说，当我们把所有可能的𝑇! 排列都考虑到的时候，对于预测词的所有上下文就都可以学习到了！
    由于遍历 𝑇! 种路径计算量非常大（对于10个词的句子，10!=3628800）。因此实际只能随机的采样𝑇!里的部分排列，并求期望；

# ELMo，(Embeddings from Language Models)
    ELMo顾名思义是从Language Models得来的embeddings，确切的说是来自于Bidirectional language models。
    利用语言模型来获得一个上下文相关的预训练表示，称为ELMo。
    与word2vec相比ELMo使上下文无关的静态(static)向量变成上下文相关的动态(dynamic)向量,一定程度解决了一词多义的问题。
    每一个词语的表征都是整个输入语句的函数。具体做法就是先在大语料上以language model为目标训练出bidirectional LSTM模型，然后利用LSTM产生词语的表征。
    在进行有监督的NLP任务时，可以将ELMo直接当做特征拼接到具体任务模型的词向量输入或者是模型的最高层表示上。
    不像传统的词向量，每一个词只对应一个词向量，ELMo利用预训练好的双向语言模型，然后根据具体输入从该语言模型中可以得到上下文依赖的当前词表示（对于不同上下文的同一个词的表示是不一样的），
    再当成特征加入到具体的NLP有监督模型里。
    引入双向语言模型，其实是2个单向语言模型（前向和后向）的集成；通过保存预训练好的2层biLSTM，通过特征集成或finetune(微调)应用于下游任务；
    缺点：本质上为自回归语言模型，只能获取单向的特征表示，不能同时获取上下文表示；LSTM不能解决长距离依赖。
    为什么不能用biLSTM构建双向语言模型？不能采取2层biLSTM同时进行特征抽取构建双向语言模型，否则会出现标签泄漏的问题；因此ELMO前向和后向的LSTM参数独立，共享词向量，独立构建语言模型；
    
# 微调(Fine-tuning, finetune)
    冻结预训练模型的部分卷积层（通常是靠近输入的多数卷积层，因为这些层保留了大量底层信息）甚至不冻结任何网络层，
    训练剩下的卷积层（通常是靠近输出的部分卷积层）和全连接层。
    只要分阶段训练，模型稍有不同，都可以叫fine-tune(微调)

# 判别性微调（Discr）
    由于不同的层捕获不同类型的信息，它们应该在不同程度上进行微调。 
    不是对模型的所有层使用相同的学习速率，而是区分性微调允许我们以不同的学习速率调整每个层。

# 倾斜的三角学习率（STLR）
    它首先线性地增加学习率，然后根据训练时间线性衰减它; 具有短期增长和长衰减期
        
# 通用语言模型微调(Universal Language Model Fine-tuning for Text Classification,ULMFiT)
    要点：三阶段训练：LM预训练+精调特定任务LM+精调特定分类任务；特征抽取：3层AWD-LSTM；精调特定分类任务：逐层解冻；
    ULMFiT由三个阶段组成：
    a）LM在一般领域语料库上进行训练，以捕获不同层次语言的一般特征。 
    b）使用判别性微调（'Discr'）和倾斜三角学习率（STLR）对目标任务数据进行微调，以学习任务特定的功能。 
    c）使用逐渐解冻，'Discr'和STLR对目标任务进行微调，以保留低级表示并适应高级表示

# SiATL(Simple Approach for Transfer Learning)
    SiATL要点：
    二阶段训练：LM预训练+特定任务精调分类任务（引入LM作为辅助目标，辅助目标对于小数据有用，与GPT相反）；
    特征抽取：LSTM+self-attention；
    精调特定分类任务：逐层解冻；

# GPT(Generative Pre-Training)
    使用的是标准的语言模型目标函数，即通过前k个词预测当前词，但是在语言模型网络上他们使用了Transformer解码器作为语言模型。
    Transformer模型主要是利用自注意力（self-attention）机制的模型
    具体NLP任务有监督微调时，与ELMo当成特征的做法不同，OpenAI GPT不需要再重新对任务构建新的模型结构，
    而是直接在transformer这个语言模型上的最后一层接上softmax作为任务输出层，然后再对这整个模型进行微调。
    GPT1.0要点：
        采用Transformer进行特征抽取，首次将Transformer应用于预训练语言模型；
        finetune阶段引入语言模型辅助目标（辅助目标对于大数据集有用，小数据反而有所下降，与SiATL相反），解决finetune过程中的灾难性遗忘；
        预训练和finetune一致，统一二阶段框架；
    GPT2.0要点：
        没有针对特定模型的精调流程：GPT2.0认为预训练中已包含很多特定任务所需的信息。
        生成任务取得很好效果，使用覆盖更广、质量更高的数据；
    缺点：
        依然为单向自回归语言模型，无法获取上下文相关的特征表示；

# BERT（Bidirectional Encoder Representation from Transformers)
    随机mask语料中15%的token，然后将masked token 位置输出的最终隐层向量送入softmax，来预测masked token。
    与ELMo相比BERT，前者训练出的词级别(word-level)向量变成后者句子级别(sentence-level)的向量
    Bert是直接在输入端显示地通过引入Mask标记，在输入侧隐藏掉一部分单词，让这些单词在预测的时候不发挥作用，要求利用上下文中其它单词去预测某个被Mask掉的单词；
    
# XLNet    
    通过Attention Mask机制，在Transformer内部随机Mask掉一部分单词（这个被Mask掉的单词比例跟当前单词在句子中的位置有关系，位置越靠前，被Mask掉的比例越高，位置越靠后，被Mask掉的比例越低），让这些被Mask掉的单词在预测某个单词的时候不发生作用。
    使用自回归语言模型，为解决双向上下文的问题，引入了排列语言模型；融合Transformer-XL的优点处理过长文本；
    
# 词向量(word embedding)
    最简单的word embedding是把词进行基于词袋（BOW）的One-Hot表示。这种表示方法学习不到单词之间的关系（位置、语义），并且如果文档中有很多词，词向量可能会很长。
    另外一种方法就是通过word2vec训练词汇，将词汇用向量表示。该模型涉及两种算法：CBOW和Skip-Gram。这种方法可以将我们语义上相似的词用相似的向量表示，但是有个缺点，同一个词只有一种语义。
    使用语言模型预训练（如ELMo，GPT和 BERT其实可以看成是一个句子级别的上下文的词表示，它可以充分利用大规模的单语语料，并且可以对一词多义进行建模。
        
# 位置向量(Position Embedding)
    将每个位置编号，然后每个编号对应一个向量，通过结合位置向量和词向量，就给每个词都引入了一定的位置信息，这样就可以分辨出不同位置的词了。
    在RNN、CNN模型中其实都出现过Position Embedding，但在那些模型中，Position Embedding是锦上添花的辅助手段，也就是“有它会更好、没它也就差一点点”的情况，
    因为RNN、CNN本身就能捕捉到位置信息。但是在这个纯Attention模型中，Position Embedding是位置信息的唯一来源，因此它是模型的核心成分之一，并非仅仅是简单的辅助手段。

# 注意力机制(attention机制)
    AttentionModel(注意力模型，AM)
    给定一组向量集合values，以及一个向量query，attention机制是一种根据该query计算values的加权求和的机制。
    attention的重点就是这个集合values中的每个value的“权值”的计算方法。
    有时候也把这种attention的机制叫做query的输出关注了原文的不同部分。
    具体过程：目标字及其上下文的字都有各自的原始Value，Attention机制将目标字作为Query、其上下文的各个字作为Key，
        并将Query与各个Key的相似性作为权重，把上下文各个字的Value融入目标字的原始Value中。
        Attention机制将目标字和上下文各个字的语义向量表示作为输入，首先通过线性变换获得目标字的Query向量表示、
        上下文各个字的Key向量表示以及目标字与上下文各个字的原始Value表示，然后计算Query向量与各个Key向量的相似度作为权重，
        加权融合目标字的Value向量和各个上下文字的Value向量，作为Attention的输出，即：目标字的增强语义向量表示。
    一个序列每个字符对其上下文字符的影响作用都不同，每个字对序列的语义信息贡献也不同，
    可以通过一种机制将原输入序列中字符向量通过加权融合序列中所有字符的语义向量信息来产生新的向量，即增强了原语义信息。
    注意力机制都可以一个三元组去描述，这个三元组是（Query，Key，Value）。
    假设我们有Q，K，V三个向量，每个输入单位（比如一个词）都具有对应的三元组的值，具体做法是将embedding后的词表示分别与Q，K，V相乘，得到最终的Q，K，V表示。
    
    
# 自注意力机制(self attention机制)
    self attention其实是对attention进行了一个更广泛的定义罢了，
    比如很多时候我们是把k和v都当成一样的算来，做self的时候还可能是quey=key=value。
    Self-Attention:
        对于输入文本，我们需要对其中的每个字分别增强语义向量表示，因此，我们分别将每个字作为Query，加权融合文本中所有字的语义信息，
        得到各个字的增强语义向量。
        在这种情况下，Query、Key和Value的向量表示均来自于同一输入文本，即 Q = K = V(后面会经过变化变的不一样)， 
        同时对attention权重做了缩放，除去了维度值。
        因此，该Attention机制也叫Self-Attention。

# 多头注意力机制(Multi-head Attention)
    为了增强Attention的多样性，进一步利用不同的Self-Attention模块获得文本中每个字在不同语义空间下的增强语义向量，
    并将每个字的多个增强语义向量进行线性组合，从而获得一个最终的与原始字向量长度相同的增强语义向量
    “多头”实际上是指在初始化Q，K，V时，使用多组初始化值。
    Transformer使用了8组，每组都是随机初始化的，在经过训练后，我们就将得到8个获取了不同权重的结果表示。
    Multi-Head Attention的结果会被输入到前馈网络层中。为了避免同时输入8个结果，我们只需要再初始化一个矩阵W，
    和8个连接起来的attention结果做乘法，最终变换成前馈网络层可以接收的大小。

# Seq2Seq
    即从序列到序列，通俗来说，就是输入一段文本，再输出一段文本
    
# encoder-decoder模型(编码-解码模型)
    Encoder-Decoder模型中的编码，就是将输入序列转化成一个固定长度的向量；解码，就是将之前生成的固定向量再转化成输出序列。
    准确的说，Encoder-Decoder并不是一个具体的模型，而是一类框架。
        
# Transformer
    依靠自注意力机制来计算其输入和输出表示的转换模型
    Transformer规定输入大小为512，这意味着我们需要对原始的输入文本进行裁剪或填充。                
    
# Transformer-XL
    XL实际上是“extra-long”的意思，这意味着Transformer-XL在模型设计上做了长度方面的延申工作。
    句段层级的循环复用; Transformer每次处理的是定长片段。那么在XL版本中，上一次处理的片段信息将会被存储起来，在当前片段的处理中会把这部分信息添加进来，这便是“延长”的含义。这样做便完成了上下文之间的迁移。
    使用相对位置编码;在Transformer中，原本的位置embedding是一种绝对位置编码，因此，当我们采用上面提到的迁移方法时，绝对编码会让网络“产生困惑”，例如片段大小为4，那么每个片段的绝对位置编码都为（0，1，2，3），这变失去了位置顺序的信息。因此在XL中，使用相对位置编码。

# 人工神经网络（Artificial Neural Network，ANN）
    简称神经网络（Neural Network，NN）或类神经网络，在机器学习和认知科学领域，是一种数学模型或计算模型，用于对函数进行估计或近似。神经网络由大量的人工神经元联结进行计算。

# 前馈神经网络（Feedforward Neural Network）
    人工智能领域中，最早发明的简单人工神经网络类型。在它内部，参数从输入层向输出层单向传播。有异于递归神经网络，它的内部不会构成有向环

# 反向传播（Backpropagation，缩写为BP）
    是“误差反向传播”的简称，是一种与最优化方法（如梯度下降法）结合使用的，用来训练人工神经网络的常见方法。
    该方法对网络中所有权重计算损失函数的梯度。这个梯度会反馈给最优化方法，用来更新权值以最小化损失函数。
    反向传播要求有对每个输入值想得到的已知输出，来计算损失函数梯度。因此，它通常被认为是一种监督式学习方法，虽然它也用在一些无监督网络（如自动编码器）中。
    它是多层前馈网络的Delta规则的推广，可以用链式法则对每层迭代计算梯度。反向传播要求人工神经元（或“节点”）的激励函数可微。

# 递归神经网络（RNN）
    是神经网络的一种。单纯的RNN因为无法处理随着递归，权重指数级爆炸或梯度消失问题，难以捕捉长期时间关联；而结合不同的LSTM可以很好解决这个问题。
    时间递归神经网络可以描述动态时间行为，因为和前馈神经网络（feedforward neural network）接受较特定结构的输入不同，RNN将状态在自身网络中循环传递，
    因此可以接受更广泛的时间序列结构输入。

# 感知机(Perceptron)
    感知即意识对内外界信息的觉察、感觉、注意、知觉的一系列过程。模拟人类感知能力的机器，称之为‘感知机’，也称‘感知器’。
    感知机是二分类问题的线性分类模型，其输入为实例的特征向量，输出为实例的类别，分别是+1和-1，属于判别模型。
    感知器使用特征向量来表示的前馈神经网络，它是一种二元分类器，把矩阵上的输入 x（实数值向量）映射到输出值 f(x)上（一个二元的值）。
    
# 多层感知机(MLP,Multilayer Perceptron)
    多层感知器（Multilayer Perceptron,缩写MLP）是一种前向结构的人工神经网络，映射一组输入向量到一组输出向量。
    MLP可以被看作是一个有向图，由多个的节点层所组成，每一层都全连接到下一层。
    除了输入节点，每个节点都是一个带有非线性激活函数的神经元（或称处理单元）。
    一种被称为反向传播算法的监督学习方法常被用来训练MLP。 
    MLP是感知器的推广，克服了感知器不能对线性不可分数据进行识别的弱点。
    
# utterance embedding 
    多轮对话的每条文本（utterance）的向量表示,即为 utterance embedding 

# context embedding
    多轮对话由每条文本（utterance）组合成utterance embedding sequence；
    utterance embedding sequence 再通过一层Gated RNN（GRU、LSTM等）把无用的utterances中的噪声滤掉，进而取最后一个时刻的隐状态得到整个多轮对话（context）的context embedding

# 随机加权平均（SWA）
随机加权平均（SWA）方法来自于集成。集成是用于提高机器学习模型性能的流行的技术。
最简单的方式为，集成可以对不同初始化的模型的若干副本进行训练，并将对副本的预测平均以得到整体的预测。但是这种方法的缺点是必须承担n个不同副本的成本。研究人员提出快照集成（Snapshot Ensembles）方法。改方法是对一个模型进行训练，并将模型收敛到几个局部最优点，保存每个最优点的权重。这样一个单一的训练就可以产生n个不同的模型，将这些预测平均就能预测出整体。

# 未登录词（Out-of-vocabulary， OOV）
    未登录词就是训练时未出现，测试时出现了的单词。
    在自然语言处理或者文本处理的时候，我们通常会有一个字词库（vocabulary）。
    这个vocabulary要么是提前加载的，或者是自己定义的，或者是从当前数据集提取的。
    假设之后你有了另一个的数据集，这个数据集中有一些词并不在你现有的vocabulary里，我们就说这些词汇是Out-of-vocabulary，简称OOV。
    
# 查找表(lookup table)  
    查找表在不同的地方，其输入输出会有所不同；有时候，查找表就是一个全连接层。只不过输入比较稀疏的(二值)向量，所以矩阵乘法不需要那些输入为零值对应的系数，只要直接查表相加就可以了。 

# 表述性状态转移（Representational State Transfer，REST）
    REST是一种软件架构风格（约束条件和原则的集合，但并不是标准）。
    REST通过资源 的角度观察网络，以URI对网络资源进行唯一标识，响应端根据请求端的不同需求，通过无状态通信，对其请求的资源进行表述。
    满足REST约束条件和原则的架构或接口，就被称为是RESTful架构或RESTful接口。
    REST将资源的状态以最适合客户端或服务端的形式从服务器端转移到客户端。（或反过来）。

# 没有免费午餐定理(No Free Lunch，简称NFL)
    无免费午餐（No Free Lunch, NFL）定理证明了任何模型在所有问题上的性能都是相同的，其总误差和模型本身是没有关系的。
    NFL 定理的一个核心前提，也就是每种问题出现的概率是均等的，每个模型用于解决所有问题时，其平均意义上的性能是一样的。
    所有模型在等概率出现的问题上都有同样的性能，这件事可以从两个角度来理解：
    一是从模型的角度来看，如果单独拿出一个特定的模型来观察的话，这个模型必然会在解决某些问题时误差较小，而在解决另一些问题时误差较大；
    二是从问题的角度来看，如果单独拿出一个特定的问题来观察的话，必然有某些模型在解决这些问题时具有较高的精度，而另一些模型的精度就没那么理想了。
    脱离问题的实际情况谈论模型优劣是没有意义的，只有让模型的特点和问题的特征相匹配，模型才能发挥最大的作用。
    NFL定理表明没有一个学习算法可以在任何领域总是产生最准确的学习器。不管采用何种学习算法，至少存在一个目标函数，能够使得随机猜测算法是更好的算法
    NFL定理最重要意义是，在脱离实际意义情况下，空泛地谈论哪种算法好毫无意义，要谈论算法优劣必须针对具体学习问题
    
# 奥卡姆剃刀（Occam's Razor）
    奥卡姆剃刀（Occam's Razor）可以理解为如果有多种模型都能够同等程度地符合同一个问题的观测结果，那就应该选择其中使用假设最少的，也就是最简单的模型。
    尽管越复杂的模型通常能得到越精确的结果，但是在结果大致相同的情况下，模型就越简单越好。本质上说，奥卡姆剃刀的关注点是模型复杂度。

# 残差连接（skip connect）
    将输出表述为输入和输入的一个非线性变换的线性叠加。有时也叫跳过连接。
    在一定程度上，网络越深表达能力越强，性能越好。不过，随着网络深度的增加，带来了许多问题，梯度消散，梯度爆炸。
    深度学习依靠误差的链式反向传播来进行参数更新，一旦其中某一个导数很小，多次连乘后梯度可能越来越小，这就是常说的梯度消散，对于深层网络，传到浅层几乎就没了。
    但是如果使用了残差，每一个导数就加上了一个恒等项1。此时就算原来的导数df/dx很小，这时候误差仍然能够有效的反向传播。
    skip connect除了改善了反向传播过程中的梯度消散问题，另外还在一定程度上缓解了权重矩阵的退化问题。
    有时候虽然梯度范数大，但是如果网络的可用自由度对这些范数的贡献非常不均衡，也就是每个层中只有少量的隐藏单元对不同的输入改变它们的激活值，
    而大部分隐藏单元对不同的输入都是相同的反应，此时整个权重矩阵的秩不高。并且随着网络层数的增加，连乘后使得整个秩变的更低。
    这也是我们常说的网络退化问题，虽然是一个很高维的矩阵，但是大部分维度却没有信息，表达能力没有看起来那么强大。
    虽然权重矩阵是一个很高维的矩阵，但是大部分维度却没有信息，使得网络的表达能力没有看起来那么强大。
    这样的情况一定程度上来自于网络的对称性，而残差连接打破了网络的对称性。
    残差连接正是强制打破了网络的对称性，提升了网络的表征能力
    
# 对称性(Symmetry)和打破对称性（symmetry breaking）    
    「对称」就是对象在变换之后，结果和变换前不变。如有一变换，前后系统的状态，等价或相同，则此变换为对称变换。
    当某一层的表示的权重相同的话，会导致下一层的单元计算结果全部相同，这意味着，特征在传递到下层时，全部压缩为一个特征了。
    我们把这种现象称为对称性(Symmetry)。
    一个全连接的神经网络，同一层中的任意神经元是同构的，对于相同的输入他们会有同样的输出，
    此时如果将参数全部初始化为相同的值，那么无论前向传播还是反向传播，参数的取值还是完全相同，学习将无法打破这种对称性，
    最终同一网络层中的各个参数仍然是相同的。
    必须随机的初始化神经网络参数的值，以打破这种对称性。
    
# 随机初始化
    将权重w全部初始化为零或相同的随机数，那么每一层所学到的参数都是一样的，因为它们的梯度一样，所以在反向传播的过程中，每一层的神经元也是相同的。
    因此会导致代价函数在开始的一段时间内，明显下降，但是一段时间以后，停止继续下降。都会导致同样的问题，即对称问题(Symmetry problem)
    初始化为较小的随机数,开始模型可以很好的运行一段时间，但是随着时间增加，前向传递时，方差开始减少，梯度也开始向零靠近，会导致梯度消失(Gradient Vanishing)。
    初始化为较大的随机数,反向传播时，倒数趋于零，梯度也会消失。此外，权重较大且当输入也很大时，如果使用sigmoid做激活函数，会使输出趋向于0和1，会导致更多问题。
    随机初始化很小的值，使得W很小是因为，可以参照激活函数sigmoid和tanh，当W很大，用W * X+b=a得到的a很大，再用对a用激活函数如sigmoid(a)，
    由于a很大了，sigmoid(a)中的a会趋向正无穷或负无穷，则函数值sigmoid(a)趋向于一个平缓的趋势，
    在梯度下降的时候计算的梯度很小，会导致学习的很慢，故使得W取一个很小的值

# 放缩点积attention（scaled dot-Product attention）
    放缩点积attention（scaled dot-Product attention）就是使用点积进行相似度计算的attention，
    只是多除了一个（为K的维度）起到调节作用，使得内积不至于太大。
    
# 隐马尔科夫模型（Hidden Markov Model，HMM）
    隐马尔可夫模型（Hidden Markov Model，HMM）是统计模型，它用来描述一个含有隐含未知参数的马尔可夫过程。
    隐马尔可夫模型(Hidden Markov model, HMM)是一种结构最简单的动态贝叶斯网的生成模型，它是一种有向图模型。
    隐马尔科夫模型是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的状态随机序列，再由各个状态生成一个可观测的随机序列的过程。
    
# 马尔可夫链(Markov chain)
    马尔可夫链（Markov chain），又称离散时间马尔可夫链（discrete-time Markov chain），为状态空间中经过从一个状态到另一个状态的转换的随机过程。
    该过程要求具备“无记忆”的性质：下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。
    这种特定类型的“无记忆性”称作马尔可夫性质。
    
# 条件随机场(conditional random field, CRF)
    HMM(隐马尔可夫模型)是CRF的一个特例。HMM等价于只有一个特征函数的CRF。
    可以用于构造在给定一组输入随机变量的条件下,另一组输出随机变量的条件概率分布模型.
    条件随机场(conditional random field)是给定随机变量X条件下,随机变量Y的马尔可夫随机场.
    Y是输出变量,表示标记序列,即状态序列,X是输入变量,也就是我们得到的需要标注的观测序列.
    我们利用训练数据集通过极大似然估计或正则化的极大似然估计得到条件概率模型,
    在预测时,我们根据给定的输入序列,求出条件概率最大的输出序列.

# LDA（Latent Dirichlet Allocation）
    LDA（Latent Dirichlet Allocation）是一种文档主题生成模型，也称为一个三层贝叶斯概率模型，包含词、主题和文档三层结构。
    所谓生成模型，就是说，我们认为一篇文章的每个词都是通过“以一定概率选择了某个主题，
    并从这个主题中以一定概率选择某个词语”这样一个过程得到。文档到主题服从多项式分布，主题到词服从多项式分布。
    LDA的目的就是要识别主题，即把文档—词汇矩阵变成文档—主题矩阵（分布）和主题—词汇矩阵（分布）


        