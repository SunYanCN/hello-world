
训练集高分，测试集预测提交后发现分数很低，为什么？
有可能是训练集和测试集分布不一致，导致模型过拟合训练集。

训练集和测试集分布不一致也被称作数据集偏移(Dataset Shift)。

一、训练集、测试集分布一致与否的判断方法：
方法1. KDE (核密度估计)分布图当我们一想到要对比训练集和测试集的分布，便是画概率密度函数直方图，但直方图看分布有两点缺陷: 受bin宽度影响大和不平滑，
因此多数人会偏向于使用核密度估计图(Kernel Density Estimation, KDE)，KDE是非参数检验，用于估计分布未知的密度函数，
相比于直方图，它受bin影响更小，绘图呈现更平滑，易于对比数据分布。

对比训练集和测试集特征分布时，我们可以用seaborn.kdeplot()进行绘图可视化，样例图和代码如下:
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# 创建样例特征
# 这里，训练集、测试集各50个样本；
train_feat = np.array([ 0.04713164, -0.59420459,  0.72722759, -1.86262763,  0.42963151,
        0.3917658 , -1.22730558,  1.75013324,  0.59274965,  1.54499907,
        0.9147363 , -1.50721661, -1.29796081, -0.52339539,  2.35084833,
       -1.14783059, -1.42782487,  2.13030133,  0.22928721, -0.95961044,
        0.46814737,  0.34063791, -1.37728727, -0.22063062,  0.68970534,
       -1.69199731, -0.75036548,  1.05619284, -1.37444014, -0.54359649,
       -2.11986533, -0.67740148, -0.06680477, -0.81678172,  0.58055085,
       -0.35116691, -0.02172894,  0.23925486, -1.45888491,  0.50292242,
       -0.17959934,  1.08117023, -1.5685712 , -0.62939644, -0.51721599,
       -1.73181535, -0.14381824, -1.07963632,  0.39406808, -0.13741855])
test_feat = np.array([-0.4164219 ,  1.55810753,  0.33469117, -0.29775228,  1.40273725,
        1.48306334,  0.6713928 ,  1.41677773,  0.5923574 ,  0.70810561,
        0.24551261,  1.2662537 , -1.5662219 , -0.56213149,  2.20130365,
       -0.27538218, -0.8462891 , -0.09568602, -0.13302627, -0.83936246,
        1.45820911, -0.7151835 , -0.67849601, -1.51662033,  0.22995397,
       -0.07458576, -0.12958228,  1.56612344, -0.1838463 , -0.30392262,
        0.9056705 ,  0.11250935,  0.6521239 , -1.13566026,  0.05185993,
       -0.86696259,  1.57733915,  0.453453  , -1.06064948, -1.10412014,
        0.01647268,  2.23964178,  2.0706573 , -0.46758033,  1.89185956,
       -0.19476342,  1.6456598 , -0.79562172,  1.03897016,  0.59991084])

# 绘KDE对比分布
sns.kdeplot(train_feat, shade = True, color='r', label = 'train')
sns.kdeplot(test_feat, shade = True, color='b', label = 'test')
plt.xlabel('Feature')
plt.legend()
plt.show()

方法2.KS检验
KDE是PDF(概率分布函数Probability Distribution Function)来对比，而KS检验是基于CDF(累计分布函数Cumulative Distribution Function)来检验两个数据分布是否一致，它也是非参数检验方法(即不知道数据分布情况)。
调用scipy.stats.ks_2samp()可轻松得到KS的统计值(最大垂直差)和假设检验下的p值：
from scipy import stats
KS_statistic, p_value = stats.ks_2samp(train_feat, test_feat)
输出：KstestResult(statistic=0.22, pvalue=0.17858668181221732)
若KS统计值小且p值大，则我们可以接受KS检验的原假设H0，即两个数据分布一致。
上面样例数据的统计值较低，p值大于10%但不是很高，因此反映分布略微不一致。
注意: p值<0.01，强烈建议拒绝原假设H0，p值越大，越倾向于原假设H0成立。

方法3. 对抗验证
对抗验证的思路是：我们构建一个分类器去分类训练集和测试集，如果模型能清楚分类，说明训练集和测试集存在明显区别(即分布不一致)，否则反之。
具体步骤如下:
训练集和测试集合并，同时新增标签‘Is_Test’去标记训练集样本为0，测试集样本为1。
构建分类器(例如LGB, XGB等)去训练混合后的数据集(可采用交叉验证的方式)，拟合目标标签‘Is_Test’。
输出交叉验证中最优的AUC分数。AUC越大(越接近1)，越说明训练集和测试集分布不一致。

二、训练集、测试集分布一致的解决方法：
方法1. 构造合适的验证集
当出现训练集和测试集分布不一致的，我们可以试图去构建跟测试集分布近似相同的验证集，保证线下验证跟线上测试分数不会抖动，这样我们就能得到稳定的指标。
三种构造合适的验证集的办法：
(1) 人工划分验证集
以时间序列举例，因为一般测试集也会是未来数据，所以我们也要保证训练集是历史数据，而划分出的验证集是未来数据，不然会发生“时间穿越”的数据泄露问题，
导致模型过拟合(例如用未来预测历史数据)，这个时候就有两种验证划分方式可参考使用：
TimeSeriesSplit：Sklearn提供的TimeSeriesSplit。
固定窗口滑动划分法：固定时间窗口，不断在数据集上滑动，获得训练集和验证集。

除了时间序列数据，其它数据集的验证集划分都要遵循一个原则，即尽可能符合测试集的数据模式。

(2) 选择和测试集最相似的样本作为验证集
前面在讲对抗验证时，我们有训练出一个分类器去分类训练集和测试集，那么自然我们也能预测出训练集属于测试集的概率(即训练集在‘Is_Test’标签下预测概率)，
我们对训练集的预测概率进行降序排列，选择概率最大的前20%样本划分作为验证集，这样我们就能从原始数据集中，得到分布跟测试集接近的一个验证集了。
之后，我们还可以评估划分好的验证集跟测试集的分布状况，评估方法：将验证集和测试集做对抗验证，若AUC越小，说明划分出的验证集和测试集分布越接近(即分类器越分不清验证集和测试集)。

(3) 有权重的交叉验证
如果我们对训练集里分布更偏向于测试集分布的样本更大的样本权重，给与测试集分布不太一致的训练集样本更小权重，也能一定程度上，帮助我们线下得到不易抖动的评估分数。
在lightgbm库的Dataset初始化参数中，便提供了样本加权的参数weight。也可将对抗验证的分类器预测训练集的Is_Test概率作为权重即可。

方法2. 删除分布不一致特征
如果我们遇到分布不一致且不太重要的特征，我们可以选择直接删去这种特征。
虽然建议的是删除分布不一致但不太重要的特征，但有时避免不了碰到分布不一致但又很重要的特征，这时候其实就需要自行取舍特征分布和特征重要性的关系了

方法3. 修正分布不一致的特征输入
当我们对比观察训练集和测试集的KDE时，若发现对数据做数学运算(例如加减乘除)或对增删样本就能修正分布，使得分布接近一致，那么我们可以试试。
比如，特征在训练集中包含0、1和-1，而测试集只有1和0样本，因此可对训练集删去了特征值为-1的样本，减少该特征在训练集和测试集的差异。

方法4. 修正分布不一致的预测输出
除了对输入特征进行分布检查，我们也可以检查目标特征的分布，看是否存在可修正的空间。

方法5. 伪标签
伪标签是半监督方法，利用未标注数据加入训练。
伪标签最常见的方法是：使用有标注的训练集训练模型M;然后用模型M预测未标注的测试集;选取测试集中预测置信度高的样本加入训练集中;
使用标注样本和高置信度的预测样本训练模型M';预测测试集，输出预测结果。
可以看到，模型的训练引入了部分测试集的样本，这样相当于引入了部分测试集的分布。
但需要注意：
(1) 相比于前面的方法，伪标签通常没有表现的很好，因为它引入的是置信度高的测试集样本，这些样本很可能跟训练集分布接近一致，所以才会预测概率高。
因此引入的测试集分布也没有很不同，所以使用时常发生过拟合的情况。
(2) 注意引入的是高置信度样本，如果引入低置信度样本，会带来很大的噪声。
另外，高置信度样本也不建议选取过多加入训练集，这也是为了避免模型过拟合。

