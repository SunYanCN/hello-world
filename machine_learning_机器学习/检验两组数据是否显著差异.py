#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# 假设检验的原理：在一定的统计假设的前提下，如果发生了小概率事件，我们就有理由怀疑假设的真实性，从而拒绝接受该假设。
# 小概率事件不会发生，是假设检验的前提。
# 英国的统计学家Ronald Fisher把1/20作为小概率标准，也就是0.05，从此0.05或者比0.05小就叫做小概率事件。这个0.05就是P Value.

# Categorical data代表了被描述对象的性质，比如一个人的性别、婚姻状况、家乡等等， Categorical data 可以用Numerical data来表示，比如说描述性别时，1代表男，2代表女，但是这些数据并没有数学意义，你不能拿他做运算。Categorical data也叫作qualitative data或是Yes/No data。
# Numerical data 具有实际测量的物理意义，比如人的身高、体重、IQ、血压等等，统计学中，Numerical data也称作quantitative data

# 如果是非数值的样本，那么可以用卡方检验。卡方检验是一种用途很广的基于卡方分布的假设检验方法，其根本思想就是在于比较理论频数和实际频数的吻合程度或拟合优度问题。其主要应用于分类变量，根据样本数据推断总体分布与期望分布是否有显著差异或推断两个分类变量是否相关或相互独立。
# 如果是数值样本，可以用柯尔莫哥洛夫-斯摩洛夫检验(K-S test)。

# 做t检验，它用于分析一组数据与另一组数据或者总体均值之间的均值差异，从而判断它们是否来自于同一个总体。
# 但是t检验有它的局限性，它无法应对多个因子变量以及因子变量有多个水平(大于2)的情况。这时，我们就需要使用方差分析了。
# 方差分析的目的是分析因子对反应变量有无显著影响，即因子的不同水平下反应变量(因变量)的均值是否有差异。

# Mann-Whitney U 检验是用得最广泛的两独立样本秩和检验方法。
# 简单的说，该检验是与独立样本t检验相对应的方法，当正态分布、方差齐性等不能达到t检验的要求时，可以使用该检验。
# 其假设基础是：若两个样本有差异，则他们的中心位置将不同。

# 非参数检验概念和适用范围如下：
# 1.非参数检验的优点是不受总体分布的限制，适用范围广，且简便易学，又称任意分布检验。
# 2.秩和检验是非参数检验中的一种，是对数据从小到大排序，该排序号在统计学上称为秩。用数据的秩代替原数据进行假设检验，秩和检验对总体分布的形状差别不敏感，只对总体分布的位置差别敏感。

# t检验有一定的前提，即要求数据分布呈对称或正态分布，至少是近似。

# t检验是不论数据的分布结构的，无论什么数据，t检验开展分析时，总是基于均数和标准差计算P值，无论是正态还是严重偏态的，特别容易受到极端值的影响，而造成统计分析结果的不稳定。
# 因此t检验在偏态分布时，是十分不靠谱的一种分析方法，它无视数据真实结构，而开展的是理论分布的探讨。

# 秩和检验不仅处理正态分布的资料与t检验不分上下，只是略处下风，但它确实在处理非正态资料方面优势明显，更为准确。

# 选用t-检验的基本前提假设是，两组样本都服从正态分布，且方差相同。

# t检验属于参数化检验方法，此类方法对数据分布有一定的假设，必要时需要首先检验样本分布是否符合该假设。

# Wilcoxon秩和检验(rank-sum test)，有时也叫Mann-Whitney U检验，是另一类非参数检验方法，它们不对数据分布作特殊假设，因而能适用于更复杂的数据分布情况。
# 而当数据实际上满足正态分布时，用 t 检验更有效。
# 秩和检验的做法是，首先将两类样本混合在一起，对所有样本按照所考察的特征从小到大排序。在两类样本中分别计算所得排序序号之和 T 1 和 T 2，称作秩和。
# 两类的样本数分别是 n 1 个和 n 2。秩和检验的基本思想是，如果一类样本的秩和显著地比另一类小（或大），则两类样本在所考察的特征上有显著差异。
# 秩和检验的统计量就是某一类（如第一类，秩和为 T 1）的秩和为了比较两类样本的秩和是否差异显著，需要比较T分布，当样本数目较大时，人们可以用正态分布来近似秩和 T 1 的分布。
# 与 t 检验相比，秩和检验没有对样本分布作任何假设，适用于更广泛的情况。另外， t 检验的目的是检验两类样本的均值是否有系统差异，而秩和检验不但受两类分布的均值的影响，也受到分布形状的影响。

# 非参数检验的意思是指整个推断过程和结论均和原总体参数无关，而不是不利用参数

# 一、T检测
# 1.1、单样本T检验（比较样本均数和总体均数）；
# 要求：正态性（可以用K-S检验法；或者直接根据直方图、P-P图，Q-Q图来观察或根据偏度峰度法来分析）
# 说明：由中心极限定理可知，即使原数据不符合正态分布，只要样本量足够大时样本均数分布仍然是正态的。
# 只要数据不是强烈的偏正态，没有明显的极端值，一般而言单样本t检验都是可以使用的，分析结果都是稳定的。

# 1.2、独立样本T检验（比较成组设计的两个样本）；
# 要求：独立性、正态性（对正态性有耐受性）、方差齐性（影响大，检验更有必要，使用Levene’s检验，两样本T检验中提供Levene’s检验）
# 说明：各样本相互独立，且均来自于正态分布的样本，各样本所在总体的方差相等；

# 1.3、配对样本T检验（如用药前和用药后的两个人群的样本、同一样品用两种方法的比较）
# 要求：正态性（配对样本等价于单样本T检验，检验的是两个样本对应的差值，初始假设为差值等于0）

# 二、单因素方差分析
# 2.1 单因素方差分析的基本思想
# 基本思想：变异分解，总变异=随机变异+处理因素导致的变异，又可以分解为总变异=组内变异+组间变异，F=组间变异/组内变异，F的值越大，处理因素的影响越大。
# 2.2 单因素方差分析的使用前提
# 独立性：不满足独立性会有很大的影响，因为信息存在“重叠”的部分
# 正态性：对正态性的要求是稳健的
# 方差齐性：检验方法除了Levene’s检验，还可以有其他的检验方法：Bartleet法（比较各组方差的加权算数平均数和几何均数）、Hartley法（样本量相同时使用）、Cochran法（样本量相同时使用）。
# 2.3 单因素方法分析的使用前提不满足时变换方法
# 对数变换、平方根变换、平方根反正弦变换、平方变换、倒数变换、Box-Cox变换（分段函数）
# 2.4 单因素方差分析的适用场景
# T检验只能检验两组样本的均数差，多组样本的时候就需采用方差分析；
# 适用场景：均数间的多重比较（全部两两比较）、各组均数的精细比较（可以指定要比较的两个组，通过设定系数）、组间均数的趋势检验（为了利用分组变量中体现出的次序信息，目的不是为了拟合线性或非线性的模型，而是希望知道因素的水平改变时均数的变化趋势）
# 2.5 方差分析结束后如均值不同可进行两两比较（事前比较、事后比较）
# LSD法：用于事先计划好的比较，最灵敏；检验水准没有校正，每次都是α
# Sidak法：第二灵敏；
# Bonferroni法：用于事先计划好的比较，第三灵敏；
# Scheffe法：多用样本含量不等的情况，第四灵敏；
# Dunnett法：常用于多个实验组和一个对照组的比较，第五灵敏；

# 寻找同质亚组的检验方法：
# S-N-K法：将所有样本分为多个子集；
# Tukey法：任意两组比较，要求样本含量相同，MEER不超过α；
# Duncan法：与SNK法类似；

# 名词释义：
# CER：每进行一次比较犯一类错误错误的概率；
# EERC：完全无效假设检验下，做完全部比较犯一类错误的概率；
# MEER：部分或者任何完全假设下，犯一类错误的最大概率值，即最大实验误差率。

# 三、非参数检验
# 1、单样本非参数检验
# 1.1、K-S检验：针对连续变量，考察是否符合正态分布
# 1.2、二项分布检验：针对两分类变量，考察是否符合二项分布
# 1.3、游程检验：考察总体的随机性
# 2、两个独立样本的非参数检验（无效假设为两样本的中心位置是否相等）
# 2.1、Mann-Whitney U检验，两样本秩和检验，应用范围最广；
# 2.2、Kolmogorov-Smirnov Z检验：检验两个样本的累积频数分布曲线，判断两个样本的分布是否相同；
# 2.3、Moses Extreme Reactions 检验：Moses极端反应检验，单侧检验
# 2.4、Wald-Wolfowitz Runs 检验：单侧检验，无论是集中趋势、离散趋势、偏度的波动情况都能检测出来，如果只是检查中心位置，最好不用，检验两样本是否来自同样的分布；

# 3、多个独立样本的非参数检验
# 3.1、Kruskal-Wallis H检验（类似Wilcoxon符号秩检验，两样本在多样本上的推广）
# 3.2、中位数检验
# 3.3、Jonckheere-Terpstra检验：对连续变量和有序分类资料都使用，分组变量为有序分类资料时，检验效能要高于Kruskal-Wallis H检验

# 4、两个配对样本（求出差值，查看中位数是否为0，目的就是为了检验均值是否相等）
# 4.1、sign符号检验：只利用了符号信息，差值是否一半为正一半为负；
# 4.2、Wilcoxon符号秩检验：利用了符号和差值的大小顺序（符号+秩序）

# 5、多个相关样本非参数检验
# 5.1、Friedman 检验：基本思想是同区组的处理值和计算的秩比较才有意义，还附带齐性子集结果给出了准确的两两比较信息；
# 5.2、Kendall协和系数检验：为了检验各组评价是否一致，Friedman检验只能说明尚不能认为有差异，但是无法评判一致性，Kendall方法针对连续变量，
# 5.3、Cochran检验：有些评价只能用是否、好坏等二元数据来判断，Cochran只适用于二分类变量，用Kendall方法会有很多的打结现象。

# 卡方检验的基本思想： 以卡方分布为基础，计算观察值和期望值之间的偏离程度；

# P-Value也称为P值,是支持原假设的概率。
# 关于p值意义:
# P＞0.05 碰巧出现的可能性大于5% ，不能否定无效假设，两组差别无显著意义
# P＜0.05 碰巧出现的可能性小于5% ，可以否定无效假设，两组差别有显著意义
# P＜0.01 碰巧出现的可能性小于1% ，可以否定无效假设，两者差别有非常显著意义
# 随着统计量增大，表示预期的分布和实际的分布的差异也就越来越大。
# 另外，由于通常意义上，p值是越小越能推翻零假设

# Z检验需要满足以下几个条件:
# 1.总体是正态分布
# 2.样本数量足够大(一般大于30即可)
# 3.总体方差(或标准差)已知
# 其中,条件1和条件3只需满足一个即可

from scipy import stats
import numpy as np
import statsmodels.stats.weightstats as sw

# 注：ttest_1samp, ttest_ind, ttest_rel均进行双侧检验
# H0:μ=μ0
# H1:μ≠μ0

def ttest_1samp():
    """
    单样本T检验-ttest_1samp
    单样本T检验（比较样本均数和总体均数）；
    要求：正态性（可以用K-S检验法；或者直接根据直方图、P-P图，Q-Q图来观察或根据偏度峰度法来分析）
    说明：由中心极限定理可知，即使原数据不符合正态分布，只要样本量足够大时样本均数分布仍然是正态的。
    只要数据不是强烈的偏正态，没有明显的极端值，一般而言单样本t检验都是可以使用的，分析结果都是稳定的。
    :return:
    """
    # 生成50行x2列的数据

    np.random.seed(7654567)  # 保证每次运行都会得到相同结果
    # 均值为5，方差为10
    rvs = stats.norm.rvs(loc=5, scale=10, size=(50,2))

    # 检验两列数的均值与1和2的差异是否显著

    stats.ttest_1samp(rvs, [1, 2])
    # 分别显示两列数的t统计量和p值。由p值分别为0.042和0.018，当p值小于0.05时，认为差异显著，即第一列数的均值不等于1，第二列数的均值不等于2。

    stats.ttest_1samp(rvs, 5.0)
    # 不拒绝原假设——均值等于5, 即认为没有显著差异；

    stats.ttest_1samp(rvs,[5.0,0.0])

def ttest_ind():
    """
    两独立样本t检验-ttest_ind
    当两总体方差相等时，即具有“方差齐性”，可以直接检验
    不拒绝原假设——两总体均值相等
    当不确定两总体方差是否相等时，应先利用levene检验，检验两总体是否具有方差齐性。
    若levene检验p值远大于0.05，则认为两总体具有方差齐性。
    如果两总体不具有方差齐性，需要将ttest_ind检验的equal_val参数设定为“False”。独立样本T检验（比较成组设计的两个样本）；
    要求：独立性、正态性（对正态性有耐受性）、方差齐性（影响大，检验更有必要，使用Levene’s检验，两样本T检验中提供Levene’s检验）
    说明：各样本相互独立，且均来自于正态分布的样本，各样本所在总体的方差相等；
    :return:
    """
    # 两独立样本t检验
    np.random.seed(12345678)
    #loc:平均值  scale：方差
    rvs1 = stats.norm.rvs(loc=5,scale=10,size=500)
    rvs2 = stats.norm.rvs(loc=5,scale=10,size=100)
    # 当两总体方差相等时，即具有“方差齐性”，可以直接检验
    # 不拒绝原假设——两总体均值相等
    stats.ttest_ind(rvs1,rvs2)

    # 当不确定两总体方差是否相等时，应先利用levene检验，检验两总体是否具有方差齐性。
    stats.levene(rvs1, rvs2)
    #p值远大于0.05，认为两总体具有方差齐性。

    #如果两总体不具有方差齐性，需要将equal_val参数设定为“False”。
    rvs1 = stats.norm.rvs(loc=5,scale=10,size=5)
    rvs2 = stats.norm.rvs(loc=5,scale=4,size=4)
    stats.ttest_ind(rvs1,rvs2, equal_var=False)

    # 需注意的情况：
    # 如果两总体具有方差齐性，错将equal_var设为False，p值变大
    # 两总体方差不等时，若没有将equal_var参数设定为False，则函数会默认equal_var为True，这样会低估p值
    # 当两样本数量不等时，equal_val的变化会导致t统计量变化
    # rvs1：来自总体——均值5，方差10，样本数500
    # rvs2：来自总体——均值5，方差20，样本数100
    # 两总体不具有方差齐性，应设定equal_var=False

def ttest_rel():
    """
    配对样本t检验配对样本T检验（如用药前和用药后的两个人群的样本、同一样品用两种方法的比较）
    要求：正态性（配对样本等价于单样本T检验，检验的是两个样本对应的差值，初始假设为差值等于0）
    :return:
    """
    np.random.seed(12345678)

    # 不拒绝原假设，认为rvs1与rvs2所代表的总体均值相等

    rvs1 = stats.norm.rvs(loc=5, scale=10, size=500)
    rvs2 = (stats.norm.rvs(loc=5, scale=10, size=500) + stats.norm.rvs(scale=0.2, size=500))
    stats.ttest_rel(rvs1, rvs2)
    # Ttest_relResult(statistic=0.24101764965300979, pvalue=0.80964043445811551)

    # 拒绝原假设，认为rvs1与rvs3所代表的总体均值不相等

    rvs3 = (stats.norm.rvs(loc=8, scale=10, size=500) + stats.norm.rvs(scale=0.2, size=500))
    stats.ttest_rel(rvs1, rvs3)

def mannwhitneyu():
    """
    非参数统计的 Mann-Whitney 秩和检验
    Mann-Whitney 秩和检验，也被称为 Mann-Whitney-U 检验。
    曼-惠特尼U检验又称“曼-惠特尼秩和检验”，是由H.B.Mann和D.R.Whitney于1947年提出的。它假设两个样本分别来自除了总体均值以外完全相同的两个总体，目的是检验这两个总体的均值是否有显著的差别。
    事实上，Wilcoxon 统计量与 Mann-Whitney 统计量是等价的。
    Wilcoxon 秩和检验主要针对两样本量相同的情况，而 Mann-Whitney 秩和检验考虑到了不等样本的情况，算是对 Wilcoxon 秩和检验这一方法的补充。
    因此，也称两样本的秩和检验为 Wilcoxon-Mann-Whitney 检验 ( 简称 W-M-W 检验 )。
    :return:
    """
    weight_high = [134, 146, 104, 119, 124, 161, 107, 83, 113, 129, 97, 123]
    weight_low = [70, 118, 101, 85, 112, 132, 94]
    stats.mannwhitneyu(weight_high, weight_low, use_continuity=True, alternative='two-sided')
    # use_continuity：是否需要0.5的连续性校正，建议小样本需要。默认值为 True 。
    # alternative：{None, ‘less’, ‘two-sided’, ‘greater’}, optional
    # ‘two-sided’ 表示双侧检验，‘greater’ 为备择假设是大于的单边检验，‘less’ 为备择假设是小于的单边检验，None 表示双侧检验 p 值的一半。默认值为 None 。
    # Out[9]: MannwhitneyuResult(statistic=62.0, pvalue=0.09934224785346528)
    # 由于p值大于0.05，故可以认为没有显著差异。

def kstest():
    """
    KS检验
    Kolmogorov-Smirnov检验是基于累计分布函数的，用于检验一个分布是否符合某种理论分布或比较两个经验分布是否有显著差异。
    单样本K-S检验是用来检验一个数据的观测经验分布是否符合已知的理论分布。
    两样本K-S检验由于对两样本的经验分布函数的位置和形状参数的差异都敏感，所以成为比较两样本的最有用且最常用的非参数方法之一。
    Kolmogorov-Smirnov是比较一个频率分布f(x)与理论分布g(x)或者两个观测值分布的检验方法。其原假设H0:两个数据分布一致或者数据符合理论分布。D=max| f(x)- g(x)|，当实际观测值D>D(n,α)则拒绝H0，否则则接受H0假设。
    KS检验与t-检验之类的其他方法不同是KS检验不需要知道数据的分布情况，可以算是一种非参数检验方法。当然这样方便的代价就是当检验的数据分布符合特定的分布事，KS检验的灵敏度没有相应的检验来的高。
    :return:
    """
    test = np.array([4949.58940397, 4712.41059603, 4426.70198675, 4427.8807947,
                     4695.1192053, 4929.2384106, 4403.08609272, 4606.33112583,
                     4599.23178808, 4523.54966887, 4551.41721854, 4784.89403974])
    stats.kstest(test, 'norm', args=(test.mean(), test.std()))
    # Out[14]: KstestResult(statistic=0.14544769279466002, pvalue=0.9614321490963473)

    rvs = [1.26, 0.34, 0.70, 1.75, 50.57, 1.55, 0.08, 0.42, 0.50, 3.20, 0.15, 0.49, 0.95, 0.24, 1.37, 0.17, 6.98,
                0.10, 0.94, 0.38]
    cdf = [2.37, 2.16, 14.82, 1.73, 41.04, 0.23, 1.32, 2.91, 39.41, 0.11, 27.44, 4.51, 0.51, 4.50, 0.18, 14.68,
                  4.66, 1.30, 2.06, 1.19]
    stats.kstest(rvs, cdf, args=(), alternative='two-sided', mode='auto')
    #其中rvs可以是数组、生成数组的函数或者scipy.stats里面理论分布的名字
    #cdf可以与rvs一致。若rvs和cdf同是数组，则是比较两数组的分布是否一致；一个是数组，另一个是理论分布的名字，则是看样本是否否和理论分布
    #args是一个元组，当rvs或者cds是理论分布时，这个参数用来存储理论分布的参数，如正态分布的mean和std。
    # 翻译结果
    # rvs：str，数组或可调用
    #         如果是字符串，则应为`scipy.stats`中的发行版名称。
    #         如果是数组，则应该是一维随机观测值的数组
    #         变量。
    #         如果是可调用的，它应该是一个生成随机变量的函数；
    #         它必须有一个关键字参数`size`。
    #     cdf：str或可调用
    #         如果是字符串，则应为`scipy.stats`中的发行版名称。
    #         如果`rvs`是一个字符串，则`cdf`可以为False或与`rvs`相同。
    #         如果是可调用的，则该可调用的用于计算cdf。
    #     args：元组，序列，可选
    #         分布参数，如果`rvs`或`cdf`是字符串，则使用。
    #     N：int，可选
    #         如果`rvs`是字符串或可调用的样本量。默认值为20。
    #     alternative：{'two-sided', 'less', 'greater'}，可选
    #         定义替代假设（请参见上面的说明）。
    #         默认值为“双面”。
    #     mode：{'auto', 'exact', 'approx', 'asymp'}，可选
    #         定义用于计算p值的分布。
    # *'auto'：选择其他选项之一。
    # *“exact”：使用测试统计信息的确切分布。
    # *'approx'：用双面概率的两倍近似双面概率
    # *'asymp'：使用检验统计量的渐近分布

def ztest():
    """
    对于大样本数据（样本量 ≥ \geq ≥ 30），或者即使是小样本，但是知道其服从正态分布，并且知道总体分布的方差时，需要用 z 检验。
    :return:
    """
    arr = [23, 36, 42, 34, 39, 34, 35, 42, 53, 28, 49, 39,
           46, 45, 39, 38, 45, 27, 43, 54, 36, 34, 48, 36,
           47, 44, 48, 45, 44, 33, 24, 40, 50, 32, 39, 31]
    # 检测其均值是否为 39， 该问题显然是一个双侧检验，由于样本个数大于 30，则使用 z 检验
    sw.ztest(arr, value=39)
    # (0.3859224924939799, 0.6995540720244979)
    # 从 ztest 的运行结果可以看出，统计量值为 0.385，而 p 值是 0.699，在置信度 α = 0.05 时，由于 p 值大于 α ，接受原假设，认为该样本的均值是 39。

    # 若要检测该样本均值是否大于 39，即原假设 H0： μ > 39 ，备选假设为： μ ≤ 39 ，则我们需要在代码中增加一个参数 alternative=``smaller”：
    sw.ztest(arr, value=39, alternative="smaller")
    # (0.3859224924939799, 0.650222963987751)
    # 检测结果的 p 值为 0.650，大于置信度 0.05，则接受原假设，认为样本均值大于39。

    # 检测两个样本的均值是否相等，因为两个样本都是大样本，使用 z 检验， python 代码如下：
    arr2 = [41, 34, 36, 32, 32, 35, 33, 31, 35, 34,
            37, 34, 31, 36, 37, 34, 33, 37, 33, 38, 38, 37, 34, 36, 36, 31, 33, 36, 37, 35, 33, 34, 33, 35, 34, 34, 34, 35, 35, 34]
    sw.ztest(arr, arr2, value=0)
    # (3.775645601380307, 0.0001595937672736755)
    # 从 ztest 的检验结果可以看出，p 值小于 0.05， 则拒绝原假设，认为两个样本的均值不相等。

def chisquare():
    observed_pd = pd.DataFrame(['1点'] * 23 + ['2点'] * 20 + ['3点'] * 18 + ['4点'] * 19 + ['5点'] * 24 + ['6点'] * 16)
    expected_pd = pd.DataFrame(['1点'] * 20 + ['2点'] * 20 + ['3点'] * 20 + ['4点'] * 20 + ['5点'] * 20 + ['6点'] * 20)
    observed = pd.crosstab(index=observed_pd[0], columns='count')
    expected = pd.crosstab(index=expected_pd[0], columns='count')
    stats.chisquare(f_obs=observed, f_exp=expected)
    # Power_divergenceResult(statistic=array([2.3]), pvalue=array([0.80626687]))
    # 可以看出P值要远大于显著性水平α=0.05，所以我们没有理由拒绝原假设，即观察频数与期望频数没有差异。

    # 假设平台从微博、微信、知乎渠道引流，现在我们要确定留存率是否与渠道有关
    df = pd.DataFrame(columns=['register', 'stay'], index=['weibo', 'zhihu', 'weixin'],
                      data=[[11570, 3173], [15113, 3901], [18244, 4899]])
    df['lost'] = df['register'] - df['stay']
    observed = df[['stay', 'lost']]
    stats.chi2_contingency(observed=observed)
    # 可以看出P值要小于我们原先定的显著性水平α，所以我们有理由拒绝原假设，即用户渠道的确影响了留存情况，两者并不是相互独立的。

    national = pd.DataFrame(["white"] * 100000 + ["hispanic"] * 60000 + \
                            ["black"] * 50000 + ["asian"] * 15000 + ["other"] * 35000)

    minnesota = pd.DataFrame(["white"] * 600 + ["hispanic"] * 300 + \
                             ["black"] * 250 + ["asian"] * 75 + ["other"] * 150)

    national_table = pd.crosstab(index=national[0], columns="count")
    minnesota_table = pd.crosstab(index=minnesota[0], columns="count")
    observed = minnesota_table
    national_ratios = national_table / len(national)  # 实际值
    expected = national_ratios * len(minnesota)  # 理论值
    chi_squared_stat = (((observed - expected) ** 2) / expected).sum()
    print(chi_squared_stat)
    crit = stats.chi2.ppf(q=0.95,  # 找到95%置信度的临界值
                          df=4)  # 自由度个数
    # ①自由度是指当以样本的统计量来估计总体参数时，样本中独立或能自由变化的数据的个数。
    # ②自由度就是能独立变化的数据数目，只要n-1个数确定，第n个数就确定了，它不能自由变化。
    print("临界值")
    print(crit)

    p_value = 1 - stats.chi2.cdf(x=chi_squared_stat,  # P值
                                 df=4)
    print("P value")
    print(p_value)
    # 由于临界值大于P值，所以得出结论，有95 % 的把握认为上述两个总体的分布不是相同的。

    # 当然也可以使用scipy.stats.chisquare() 函数，十分快捷！

    stats.chisquare(f_obs=observed,  # 观察值
                    f_exp=expected)  # 理论值

    observed = [5, 82, 251]
    expected = [13.52, 108.16, 216.32]
    output = stats.chisquare(observed, expected)
    print('statistic: {:.2f}, pvalue: {:.4f}'.format(output.statistic, output.pvalue))
    # statistic: 17.26, pvalue: 0.0002
def main():
    pass

if __name__ == '__main__':
    main()