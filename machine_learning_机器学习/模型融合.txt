
不相关的预测结果的集成明显比相关的集成结果要好；
当模型预测是高度相关的，当我们投票时，可以看到准确率没有提高；
高度不相关的模型，哪怕性能相对较差，集成投票也可以得到较好的结果；
集成低相关性的模型结果，可以增加纠错能力；

加权投票：
通常我们希望模型越好，其权重就越高。

当平均多个来自不同模型的输出时，会出现一些问题。并不是所有的预测器的结果是完美 校准的， 它们可能会产生过高或过低的预测概率，或者预测在一定的范围里非常混乱。
所以，这个时候，需要先将各个模型结果进行标准化；使之得分是0-1之前，且是均匀分布；

# 模型堆叠泛化集成示例：
https://machinelearningmastery.com/stacking-ensemble-for-deep-learning-neural-networks/

模型相关性可以通过相关系数来评估：
r, p = stats.pearsonr(df['模型1得分'].values,df['模型2得分'].values)
print("皮尔逊相关系数: {}\n双尾 p 值:{} (p值越小，表示相关系数越显著,p 值大致表示不相关系统的概率)".format(r, p))

相关系数 
0.8-1.0 极强相关
0.6-0.8 强相关
0.4-0.6 中等程度相关
0.2-0.4 弱相关
0.0-0.2 极弱相关或无相关
相关系数就是越接近于1或者-1就是相关的.p值的话,p值越小,一般小于0.05（或者要求的严格点的话小于0.01）说明变量之间的相关是显著的,即两个变量之间是显著相关的.

一般来说，取绝对值后，0-0.09为没有相关性，0.3-弱，0.1-0.3为弱相关，0.3-0.5为中等相关，0.5-1.0为强相关。
但是，往往你还需要做显著性差异检验，即t-test，来检验两组数据是否显著相关。
样本数越是大，需要达到显著性相关的相关系数就会越小。
所以这关系到你的样本大小，如果你的样本很大，比如说超过300，往往分析出来的相关系数比较低，比如0.2，因为你样本量的增大造成了差异的增大，但显著性检验却认为这是极其显著的相关。
一般来说，我们判断强弱主要看显著性，而非相关系数本身。




